{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-be2cf2602bbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "#from keras.layers import LeakyReLU\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tf.__version__)  # for Python 3\n",
    "#from Data_Preparation_5 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '//ibs9010/current_data/Data_Keshav/Cropped_Images/trial5/'\n",
    "CATEGORIES = [\"Background\",\"Neuron\"]\n",
    "def create_training_data():\n",
    "    Training_Data = []\n",
    "    img_size = 70\n",
    "    X = []\n",
    "    y = []\n",
    "    for categories in CATEGORIES:\n",
    "        Path = os.path.join(DATADIR,categories) # gives the path to the images; Data/Train/Image or Background\n",
    "        print(Path)\n",
    "        class_num = CATEGORIES.index(categories) # numbers the classes\n",
    "        print(class_num)\n",
    "        try:\n",
    "            for img in os.listdir(Path): #gives the images from the path\n",
    "                img_array = cv2.imread(os.path.join(Path,img),cv2.IMREAD_GRAYSCALE) \n",
    "                Training_Data.append([img_array,class_num])\n",
    "                #plt.imshow(img_array,cmap='gray')\n",
    "                #plt.show()\n",
    "                #break\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    random.shuffle(Training_Data) # do it before conversion to array as list is mutable\n",
    "    \n",
    "    for features,labels in Training_Data:\n",
    "        X.append(features)\n",
    "        y.append(labels)\n",
    "    #try:\n",
    "    X = np.array(X).reshape(-1,img_size,img_size,1) # converts it to arrays with shape (number of images,dim of image)\n",
    "    y = np.array(y)\n",
    "    X = X/255.0 # this is normalization of only the images\n",
    "    #except Exception as e:\n",
    "     #       pass\n",
    "    #print(y[5])\n",
    "    return X,y\n",
    "\n",
    "X,y = create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def binary_classification_model():\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding = 'same',input_shape=(X.shape[1:]),kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding = 'same',input_shape=(X.shape[1:]),kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(256,(3,3),padding = 'same',input_shape=(X.shape[1:]),kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding = 'same',input_shape=(X.shape[1:]),kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding = 'same',kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\")) # added a hidden layer\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\")) # added a new hidden layer\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\")) # added a new hidden layer\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\")) # added a new hidden layer\n",
    "\n",
    "model.add(Dense(2))\n",
    "#model.add(Dense(4))\n",
    "model.add(Activation('softmax')) # chaging from sigmoid to softmax to include more classes\n",
    "\n",
    "########################\n",
    "#class_weight = {0: 1., 1: 15.}\n",
    "#class_weight = {0: 5, 1: 10., 2: 1., 3:5.}\n",
    "########################\n",
    "\n",
    "#filepath=\"weights.best.hdf5\"\n",
    "ada = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss =\"categorical_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "y_train=to_categorical(y, num_classes=2)\n",
    "\n",
    "model.summary()\n",
    "#lr_model_history=model.fit(X,y_train,batch_size=64,epochs= 10,validation_split=0.1,class_weight=class_weight)\n",
    "lr_model_history=model.fit(X,y_train,batch_size=64,epochs= 50,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"//ibs9010/current_data/Data_Keshav/image/Classification_model/NeuronClassifierModels/BinaryClassifier_trial5_bigmodel.h5\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,5))\n",
    "ax.plot(np.sqrt(lr_model_history.history['loss']), 'r', label='training')\n",
    "ax.plot(np.sqrt(lr_model_history.history['val_loss']), 'b' ,label='validation')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,5))\n",
    "ax.plot(np.sqrt(lr_model_history.history['Accuracy']), 'r', label='training')\n",
    "ax.plot(np.sqrt(lr_model_history.history['val_accuracy']), 'b' ,label='validation')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#import keras\n",
    "#import tensorflow as tf \n",
    "from keras.models import load_model\n",
    "model = load_model('//ibs9010/current_data/Data_Keshav/image/Classification_model/NeuronClassifierModels/BinaryClassifier_manual_every5thsection_15epoch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on all Tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "img_size = 70 # fix the size of the image\n",
    "Path = \"//ibs9010/current_data/Data_Keshav/Cropped_Images/MG48_3day_bs/S51/\" \n",
    "#Path = \"//ibs9010/current_data/Data_Keshav/image/Classifiction_model/Data/Test/\"\n",
    "#Path = '//ibs9010/current_data/Data_Keshav/image/Classification_model/testingcrop/S055/'\n",
    "Testing_image = []# list of testing images\n",
    "image_name = []# list of image names\n",
    "\n",
    "for img in os.listdir(Path): #gives the images from the path\n",
    "    img_array = cv2.imread(os.path.join(Path,img),cv2.IMREAD_GRAYSCALE) # read every image in gray scale from the given path\n",
    "    Testing_image.append(img_array)\n",
    "    image_name.append(img)\n",
    "    \n",
    "print(\"Number of test images:\",len(Testing_image))\n",
    "#Running Inference\n",
    "Test_image = np.array(Testing_image).reshape(-1,img_size,img_size,1)\n",
    "#make an array of every element of list from Testing_image and then reshape them\n",
    "Test_image = Test_image/255.0\n",
    "scores = model.predict_classes(Test_image)\n",
    "\n",
    "# Results\n",
    "neuron_image_counter = bkgd_image_counter = 0\n",
    "for i in range(len(Test_image)):\n",
    "    #print(\"Image:\",image_name[i],\"with score:\",scores[i]) \n",
    "    if scores[i]==0:\n",
    "        bkgd_image_counter +=1\n",
    "    if scores[i]==1:\n",
    "        neuron_image_counter += 1\n",
    "    \n",
    "print(\"Total testing images:\",len(Testing_image))\n",
    "print(\"bkgd_image_counter:\",bkgd_image_counter,\"neuron_image_counter:\",neuron_image_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving classified tiles into respective folders\n",
    "\n",
    "# saving the single neuron tiles into a particular folder for now \n",
    "dest_path = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Inference/BinaryClasses/singleneurontiles'\n",
    "#dest_path = \"//ibs9010/current_data/Data_Keshav/image/Classification_model/Inference/BinaryClasses/NewTestsingleneurontiles\"\n",
    "directory = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Data/Test/'\n",
    "\n",
    "# Delete all exiting images\n",
    "import glob\n",
    "os.chdir(dest_path)\n",
    "files=glob.glob('*.tif')\n",
    "for filename in files:\n",
    "    os.unlink(filename)\n",
    "    \n",
    "#need the images of class1 to be appended in a separate list\n",
    "single_image_list  = [] # contains list of filenames of single neurons\n",
    "#sn_images = [] # conatins tiles of single neurons #(actual images itself)\n",
    "for k in range(1,len(Test_image)):\n",
    "    if scores[k]==1:\n",
    "        #print(Test_image[i])\n",
    "        #print(\"Image \",image_name[k])\n",
    "        #sn_images.append(Test_image[i])\n",
    "        single_image_list.append(image_name[k])\n",
    "        \n",
    "print(len(single_image_list))  \n",
    "#image_name[i]\n",
    "for i in range(len(Test_image)):\n",
    "    if scores[i]==1:\n",
    "        #print(\"Image:\",image_name[i])\n",
    "        #print(\"TestImage:\",Test_image[i])\n",
    "        #cv2.imwrite(image_name[i], Test_image[i])\n",
    "        cv2.imwrite(os.path.join(dest_path,image_name[i]), Test_image[i]*255)\n",
    "        #pass\n",
    "\n",
    "# Generating Pickle files for classified tiles\n",
    "## To be used for generating landmarks\n",
    "\n",
    "# Generating pickle file For Single neurons\n",
    "import pickle\n",
    "with open('//ibs9010/current_data/Data_Keshav/image/Classification_model/17aug_10thsection_binary_SN_MG48_S51.pkl', 'wb') as f:\n",
    "    pickle.dump(single_image_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the bkgd neuron tiles into a particular folder for now - as a adhoc fix!\n",
    "import os\n",
    "import cv2\n",
    "#dest_path = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Inference/BinaryClasses/NewTestbackgroundneurontiles'\n",
    "dest_path = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Inference/BinaryClasses/backgroundneurontiles'\n",
    "directory = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Data/Test/'\n",
    "\n",
    "# Delete all exiting images\n",
    "import glob\n",
    "os.chdir(dest_path)\n",
    "files=glob.glob('*.tif')\n",
    "for filename in files:\n",
    "    os.unlink(filename)\n",
    "\n",
    "#need the images of class1 to be appended in a separate list\n",
    "bkgd_image_list  = [] # contains list of filenames of single neurons\n",
    "#sn_images = [] # conatins tiles of single neurons #(actual images itself)\n",
    "for k in range(1,len(Test_image)):\n",
    "    if scores[k]==0:\n",
    "        #print(Test_image[i])\n",
    "        #print(\"Image \",image_name[k])\n",
    "        #sn_images.append(Test_image[i])\n",
    "        bkgd_image_list.append(image_name[k])\n",
    "        \n",
    "print(len(bkgd_image_list))  \n",
    "#image_name[i]\n",
    "for i in range(len(Test_image)):\n",
    "    if scores[i]==0:\n",
    "        #print(\"Image:\",image_name[i])\n",
    "        #print(\"TestImage:\",Test_image[i])\n",
    "        #cv2.imwrite(image_name[i], Test_image[i])\n",
    "        cv2.imwrite(os.path.join(dest_path,image_name[i]), Test_image[i]*255)\n",
    "        #pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
