{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from Data_Preparation_1 import *\n",
    "from keras.utils import to_categorical\n",
    "#from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//ibs9010/current_data/Data_Keshav/Cropped_Images/trial/Background\n",
      "2\n",
      "2\n",
      "0\n",
      "//ibs9010/current_data/Data_Keshav/Cropped_Images/trial/Neuron\n",
      "2\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "X,y = create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 70, 70, 128)       1280      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 70, 70, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 35, 35, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 35, 35, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 17, 17, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 214,914\n",
      "Trainable params: 214,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2983 samples, validate on 332 samples\n",
      "Epoch 1/500\n",
      "2983/2983 [==============================] - 38s 13ms/sample - loss: 0.4780 - accuracy: 0.7690 - val_loss: 0.3569 - val_accuracy: 0.8404\n",
      "Epoch 2/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.3514 - accuracy: 0.8572 - val_loss: 0.3126 - val_accuracy: 0.8825\n",
      "Epoch 3/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.2927 - accuracy: 0.8790 - val_loss: 0.2759 - val_accuracy: 0.8886\n",
      "Epoch 4/500\n",
      "2983/2983 [==============================] - 34s 12ms/sample - loss: 0.2657 - accuracy: 0.8864 - val_loss: 0.2615 - val_accuracy: 0.8916\n",
      "Epoch 5/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 0.2603 - accuracy: 0.8921 - val_loss: 0.2459 - val_accuracy: 0.9006\n",
      "Epoch 6/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 0.2225 - accuracy: 0.9102 - val_loss: 0.2478 - val_accuracy: 0.9036\n",
      "Epoch 7/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 0.2315 - accuracy: 0.8994 - val_loss: 0.2494 - val_accuracy: 0.9036\n",
      "Epoch 8/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.1977 - accuracy: 0.9185 - val_loss: 0.2567 - val_accuracy: 0.8976\n",
      "Epoch 9/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 0.1778 - accuracy: 0.9276 - val_loss: 0.2716 - val_accuracy: 0.8735\n",
      "Epoch 10/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 0.1713 - accuracy: 0.9316 - val_loss: 0.2602 - val_accuracy: 0.9006\n",
      "Epoch 11/500\n",
      "2983/2983 [==============================] - 34s 12ms/sample - loss: 0.1495 - accuracy: 0.9390 - val_loss: 0.2930 - val_accuracy: 0.8916\n",
      "Epoch 12/500\n",
      "2983/2983 [==============================] - 34s 12ms/sample - loss: 0.1287 - accuracy: 0.9494 - val_loss: 0.2727 - val_accuracy: 0.9006\n",
      "Epoch 13/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.1126 - accuracy: 0.9557 - val_loss: 0.3647 - val_accuracy: 0.8976\n",
      "Epoch 14/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 0.0995 - accuracy: 0.9621 - val_loss: 0.2482 - val_accuracy: 0.8976\n",
      "Epoch 15/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 0.0910 - accuracy: 0.9648 - val_loss: 0.3289 - val_accuracy: 0.9066\n",
      "Epoch 16/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0614 - accuracy: 0.9762 - val_loss: 0.3231 - val_accuracy: 0.9127\n",
      "Epoch 17/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 0.0544 - accuracy: 0.9802 - val_loss: 0.2898 - val_accuracy: 0.9187\n",
      "Epoch 18/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 0.0573 - accuracy: 0.9782 - val_loss: 0.3119 - val_accuracy: 0.9096\n",
      "Epoch 19/500\n",
      "2983/2983 [==============================] - 37s 12ms/sample - loss: 0.0906 - accuracy: 0.9661 - val_loss: 0.3035 - val_accuracy: 0.9157\n",
      "Epoch 20/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.4792 - val_accuracy: 0.8916\n",
      "Epoch 21/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.0440 - accuracy: 0.9849 - val_loss: 0.4379 - val_accuracy: 0.8886\n",
      "Epoch 22/500\n",
      "2983/2983 [==============================] - 43s 15ms/sample - loss: 0.0647 - accuracy: 0.9769 - val_loss: 0.3635 - val_accuracy: 0.9217\n",
      "Epoch 23/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.4099 - val_accuracy: 0.9127\n",
      "Epoch 24/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.4291 - val_accuracy: 0.9096\n",
      "Epoch 25/500\n",
      "2983/2983 [==============================] - 52s 18ms/sample - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.4587 - val_accuracy: 0.9127\n",
      "Epoch 26/500\n",
      "2983/2983 [==============================] - 41s 14ms/sample - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.3730 - val_accuracy: 0.9217\n",
      "Epoch 27/500\n",
      "2983/2983 [==============================] - 37s 12ms/sample - loss: 0.0265 - accuracy: 0.9896 - val_loss: 0.4283 - val_accuracy: 0.9307\n",
      "Epoch 28/500\n",
      "2983/2983 [==============================] - 38s 13ms/sample - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.5557 - val_accuracy: 0.8976\n",
      "Epoch 29/500\n",
      "2983/2983 [==============================] - 42s 14ms/sample - loss: 0.0566 - accuracy: 0.9816 - val_loss: 0.3191 - val_accuracy: 0.9187\n",
      "Epoch 30/500\n",
      "2983/2983 [==============================] - 40s 13ms/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.4636 - val_accuracy: 0.9157\n",
      "Epoch 31/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.0126 - accuracy: 0.9973 - val_loss: 0.4195 - val_accuracy: 0.8946\n",
      "Epoch 32/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.4658 - val_accuracy: 0.9096\n",
      "Epoch 33/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.6125 - val_accuracy: 0.8976\n",
      "Epoch 34/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.5206 - val_accuracy: 0.9157\n",
      "Epoch 35/500\n",
      "2983/2983 [==============================] - 37s 12ms/sample - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.5342 - val_accuracy: 0.9066\n",
      "Epoch 36/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 5.4671e-04 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.9066\n",
      "Epoch 37/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 2.0855e-04 - accuracy: 1.0000 - val_loss: 0.6017 - val_accuracy: 0.9096\n",
      "Epoch 38/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 1.3011e-04 - accuracy: 1.0000 - val_loss: 0.6235 - val_accuracy: 0.9096\n",
      "Epoch 39/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 9.9883e-05 - accuracy: 1.0000 - val_loss: 0.6385 - val_accuracy: 0.9127\n",
      "Epoch 40/500\n",
      "2983/2983 [==============================] - 37s 12ms/sample - loss: 8.0169e-05 - accuracy: 1.0000 - val_loss: 0.6536 - val_accuracy: 0.9096\n",
      "Epoch 41/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 6.7637e-05 - accuracy: 1.0000 - val_loss: 0.6651 - val_accuracy: 0.9127\n",
      "Epoch 42/500\n",
      "2983/2983 [==============================] - 34s 12ms/sample - loss: 5.7408e-05 - accuracy: 1.0000 - val_loss: 0.6755 - val_accuracy: 0.9127\n",
      "Epoch 43/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 5.0029e-05 - accuracy: 1.0000 - val_loss: 0.6848 - val_accuracy: 0.9127\n",
      "Epoch 44/500\n",
      "2983/2983 [==============================] - 37s 13ms/sample - loss: 4.4281e-05 - accuracy: 1.0000 - val_loss: 0.6940 - val_accuracy: 0.9127\n",
      "Epoch 45/500\n",
      "2983/2983 [==============================] - 34s 12ms/sample - loss: 3.9318e-05 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.9127\n",
      "Epoch 46/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 3.5134e-05 - accuracy: 1.0000 - val_loss: 0.7104 - val_accuracy: 0.9127\n",
      "Epoch 47/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 3.1849e-05 - accuracy: 1.0000 - val_loss: 0.7178 - val_accuracy: 0.9127\n",
      "Epoch 48/500\n",
      "2983/2983 [==============================] - 37s 12ms/sample - loss: 2.8890e-05 - accuracy: 1.0000 - val_loss: 0.7245 - val_accuracy: 0.9127\n",
      "Epoch 49/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 2.6473e-05 - accuracy: 1.0000 - val_loss: 0.7314 - val_accuracy: 0.9127\n",
      "Epoch 50/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 2.4295e-05 - accuracy: 1.0000 - val_loss: 0.7376 - val_accuracy: 0.9127\n",
      "Epoch 51/500\n",
      "2983/2983 [==============================] - 37s 12ms/sample - loss: 2.2304e-05 - accuracy: 1.0000 - val_loss: 0.7440 - val_accuracy: 0.9127\n",
      "Epoch 52/500\n",
      "2983/2983 [==============================] - 40s 13ms/sample - loss: 2.0646e-05 - accuracy: 1.0000 - val_loss: 0.7494 - val_accuracy: 0.9127\n",
      "Epoch 53/500\n",
      "2983/2983 [==============================] - 37s 12ms/sample - loss: 1.9142e-05 - accuracy: 1.0000 - val_loss: 0.7556 - val_accuracy: 0.9127\n",
      "Epoch 54/500\n",
      "2983/2983 [==============================] - 38s 13ms/sample - loss: 1.7738e-05 - accuracy: 1.0000 - val_loss: 0.7610 - val_accuracy: 0.9127\n",
      "Epoch 55/500\n",
      "2983/2983 [==============================] - 40s 13ms/sample - loss: 1.6476e-05 - accuracy: 1.0000 - val_loss: 0.7661 - val_accuracy: 0.9127\n",
      "Epoch 56/500\n",
      "2983/2983 [==============================] - 37s 12ms/sample - loss: 1.5411e-05 - accuracy: 1.0000 - val_loss: 0.7715 - val_accuracy: 0.9127\n",
      "Epoch 57/500\n",
      "2983/2983 [==============================] - 39s 13ms/sample - loss: 1.4413e-05 - accuracy: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.9127\n",
      "Epoch 58/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.3524e-05 - accuracy: 1.0000 - val_loss: 0.7812 - val_accuracy: 0.9127\n",
      "Epoch 59/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.2715e-05 - accuracy: 1.0000 - val_loss: 0.7859 - val_accuracy: 0.9127\n",
      "Epoch 60/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.1942e-05 - accuracy: 1.0000 - val_loss: 0.7906 - val_accuracy: 0.9127\n",
      "Epoch 61/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.1260e-05 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.9127\n",
      "Epoch 62/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.0626e-05 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.9127\n",
      "Epoch 63/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 1.0042e-05 - accuracy: 1.0000 - val_loss: 0.8038 - val_accuracy: 0.9127\n",
      "Epoch 64/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 9.4909e-06 - accuracy: 1.0000 - val_loss: 0.8080 - val_accuracy: 0.9127\n",
      "Epoch 65/500\n",
      "2983/2983 [==============================] - 36s 12ms/sample - loss: 9.0063e-06 - accuracy: 1.0000 - val_loss: 0.8121 - val_accuracy: 0.9127\n",
      "Epoch 66/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 8.5333e-06 - accuracy: 1.0000 - val_loss: 0.8164 - val_accuracy: 0.9127\n",
      "Epoch 67/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 8.0770e-06 - accuracy: 1.0000 - val_loss: 0.8203 - val_accuracy: 0.9127\n",
      "Epoch 68/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 7.6832e-06 - accuracy: 1.0000 - val_loss: 0.8243 - val_accuracy: 0.9127\n",
      "Epoch 69/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.3198e-06 - accuracy: 1.0000 - val_loss: 0.8282 - val_accuracy: 0.9127\n",
      "Epoch 70/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.9655e-06 - accuracy: 1.0000 - val_loss: 0.8322 - val_accuracy: 0.9127\n",
      "Epoch 71/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.6207e-06 - accuracy: 1.0000 - val_loss: 0.8355 - val_accuracy: 0.9127\n",
      "Epoch 72/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.3171e-06 - accuracy: 1.0000 - val_loss: 0.8395 - val_accuracy: 0.9127\n",
      "Epoch 73/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.0186e-06 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.9127\n",
      "Epoch 74/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.7569e-06 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.9157\n",
      "Epoch 75/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.4903e-06 - accuracy: 1.0000 - val_loss: 0.8502 - val_accuracy: 0.9157\n",
      "Epoch 76/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.2518e-06 - accuracy: 1.0000 - val_loss: 0.8535 - val_accuracy: 0.9157\n",
      "Epoch 77/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.0178e-06 - accuracy: 1.0000 - val_loss: 0.8572 - val_accuracy: 0.9157\n",
      "Epoch 78/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.8078e-06 - accuracy: 1.0000 - val_loss: 0.8605 - val_accuracy: 0.9157\n",
      "Epoch 79/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.6216e-06 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.9157\n",
      "Epoch 80/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.4104e-06 - accuracy: 1.0000 - val_loss: 0.8675 - val_accuracy: 0.9157\n",
      "Epoch 81/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.2288e-06 - accuracy: 1.0000 - val_loss: 0.8708 - val_accuracy: 0.9157\n",
      "Epoch 82/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.0587e-06 - accuracy: 1.0000 - val_loss: 0.8742 - val_accuracy: 0.9157\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.9027e-06 - accuracy: 1.0000 - val_loss: 0.8773 - val_accuracy: 0.9157\n",
      "Epoch 84/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.7469e-06 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.9157\n",
      "Epoch 85/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.5965e-06 - accuracy: 1.0000 - val_loss: 0.8839 - val_accuracy: 0.9157\n",
      "Epoch 86/500\n",
      "2983/2983 [==============================] - 35s 12ms/sample - loss: 3.4590e-06 - accuracy: 1.0000 - val_loss: 0.8871 - val_accuracy: 0.9157\n",
      "Epoch 87/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.3236e-06 - accuracy: 1.0000 - val_loss: 0.8902 - val_accuracy: 0.9157\n",
      "Epoch 88/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.2009e-06 - accuracy: 1.0000 - val_loss: 0.8932 - val_accuracy: 0.9157\n",
      "Epoch 89/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.0767e-06 - accuracy: 1.0000 - val_loss: 0.8964 - val_accuracy: 0.9157\n",
      "Epoch 90/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.9611e-06 - accuracy: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.9157\n",
      "Epoch 91/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.8485e-06 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.9157\n",
      "Epoch 92/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.7450e-06 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.9157\n",
      "Epoch 93/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 2.6477e-06 - accuracy: 1.0000 - val_loss: 0.9086 - val_accuracy: 0.9157\n",
      "Epoch 94/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.5421e-06 - accuracy: 1.0000 - val_loss: 0.9116 - val_accuracy: 0.9157\n",
      "Epoch 95/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.4497e-06 - accuracy: 1.0000 - val_loss: 0.9146 - val_accuracy: 0.9157\n",
      "Epoch 96/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 2.3630e-06 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.9157\n",
      "Epoch 97/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.2780e-06 - accuracy: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.9157\n",
      "Epoch 98/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.1947e-06 - accuracy: 1.0000 - val_loss: 0.9234 - val_accuracy: 0.9157\n",
      "Epoch 99/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.1170e-06 - accuracy: 1.0000 - val_loss: 0.9265 - val_accuracy: 0.9157\n",
      "Epoch 100/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.0422e-06 - accuracy: 1.0000 - val_loss: 0.9292 - val_accuracy: 0.9157\n",
      "Epoch 101/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.9728e-06 - accuracy: 1.0000 - val_loss: 0.9323 - val_accuracy: 0.9157\n",
      "Epoch 102/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.9070e-06 - accuracy: 1.0000 - val_loss: 0.9351 - val_accuracy: 0.9157\n",
      "Epoch 103/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.8406e-06 - accuracy: 1.0000 - val_loss: 0.9384 - val_accuracy: 0.9157\n",
      "Epoch 104/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.7748e-06 - accuracy: 1.0000 - val_loss: 0.9409 - val_accuracy: 0.9157\n",
      "Epoch 105/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.7094e-06 - accuracy: 1.0000 - val_loss: 0.9438 - val_accuracy: 0.9157\n",
      "Epoch 106/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.6484e-06 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.9157\n",
      "Epoch 107/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5906e-06 - accuracy: 1.0000 - val_loss: 0.9495 - val_accuracy: 0.9157\n",
      "Epoch 108/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5378e-06 - accuracy: 1.0000 - val_loss: 0.9524 - val_accuracy: 0.9157\n",
      "Epoch 109/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.4840e-06 - accuracy: 1.0000 - val_loss: 0.9555 - val_accuracy: 0.9157\n",
      "Epoch 110/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.4340e-06 - accuracy: 1.0000 - val_loss: 0.9580 - val_accuracy: 0.9157\n",
      "Epoch 111/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.3839e-06 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.9157\n",
      "Epoch 112/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.3339e-06 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.9157\n",
      "Epoch 113/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.2911e-06 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.9157\n",
      "Epoch 114/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.2478e-06 - accuracy: 1.0000 - val_loss: 0.9695 - val_accuracy: 0.9157\n",
      "Epoch 115/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.2067e-06 - accuracy: 1.0000 - val_loss: 0.9724 - val_accuracy: 0.9157\n",
      "Epoch 116/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.1652e-06 - accuracy: 1.0000 - val_loss: 0.9750 - val_accuracy: 0.9157\n",
      "Epoch 117/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.1286e-06 - accuracy: 1.0000 - val_loss: 0.9777 - val_accuracy: 0.9157\n",
      "Epoch 118/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.0920e-06 - accuracy: 1.0000 - val_loss: 0.9803 - val_accuracy: 0.9157\n",
      "Epoch 119/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.0556e-06 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.9157\n",
      "Epoch 120/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.0211e-06 - accuracy: 1.0000 - val_loss: 0.9859 - val_accuracy: 0.9157\n",
      "Epoch 121/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 9.8890e-07 - accuracy: 1.0000 - val_loss: 0.9886 - val_accuracy: 0.9157\n",
      "Epoch 122/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 9.5525e-07 - accuracy: 1.0000 - val_loss: 0.9913 - val_accuracy: 0.9157\n",
      "Epoch 123/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 9.2364e-07 - accuracy: 1.0000 - val_loss: 0.9938 - val_accuracy: 0.9157\n",
      "Epoch 124/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 8.9499e-07 - accuracy: 1.0000 - val_loss: 0.9965 - val_accuracy: 0.9157\n",
      "Epoch 125/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 8.6530e-07 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.9157\n",
      "Epoch 126/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 8.3761e-07 - accuracy: 1.0000 - val_loss: 1.0020 - val_accuracy: 0.9157\n",
      "Epoch 127/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 8.1059e-07 - accuracy: 1.0000 - val_loss: 1.0045 - val_accuracy: 0.9157\n",
      "Epoch 128/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.8522e-07 - accuracy: 1.0000 - val_loss: 1.0073 - val_accuracy: 0.9157\n",
      "Epoch 129/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.6052e-07 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.9157\n",
      "Epoch 130/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.3650e-07 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.9157\n",
      "Epoch 131/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.1273e-07 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.9157\n",
      "Epoch 132/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.9059e-07 - accuracy: 1.0000 - val_loss: 1.0177 - val_accuracy: 0.9157\n",
      "Epoch 133/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.6905e-07 - accuracy: 1.0000 - val_loss: 1.0204 - val_accuracy: 0.9157\n",
      "Epoch 134/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.4703e-07 - accuracy: 1.0000 - val_loss: 1.0230 - val_accuracy: 0.9157\n",
      "Epoch 135/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.2813e-07 - accuracy: 1.0000 - val_loss: 1.0256 - val_accuracy: 0.9157\n",
      "Epoch 136/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.0731e-07 - accuracy: 1.0000 - val_loss: 1.0282 - val_accuracy: 0.9157\n",
      "Epoch 137/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 5.8892e-07 - accuracy: 1.0000 - val_loss: 1.0308 - val_accuracy: 0.9157\n",
      "Epoch 138/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.6938e-07 - accuracy: 1.0000 - val_loss: 1.0332 - val_accuracy: 0.9157\n",
      "Epoch 139/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.5184e-07 - accuracy: 1.0000 - val_loss: 1.0359 - val_accuracy: 0.9157\n",
      "Epoch 140/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.3482e-07 - accuracy: 1.0000 - val_loss: 1.0385 - val_accuracy: 0.9157\n",
      "Epoch 141/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.1879e-07 - accuracy: 1.0000 - val_loss: 1.0411 - val_accuracy: 0.9157\n",
      "Epoch 142/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.0189e-07 - accuracy: 1.0000 - val_loss: 1.0436 - val_accuracy: 0.9157\n",
      "Epoch 143/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.8618e-07 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.9157\n",
      "Epoch 144/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.7240e-07 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.9157\n",
      "Epoch 145/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.5797e-07 - accuracy: 1.0000 - val_loss: 1.0512 - val_accuracy: 0.9157\n",
      "Epoch 146/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 4.4310e-07 - accuracy: 1.0000 - val_loss: 1.0538 - val_accuracy: 0.9127\n",
      "Epoch 147/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 4.2988e-07 - accuracy: 1.0000 - val_loss: 1.0563 - val_accuracy: 0.9127\n",
      "Epoch 148/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 4.1773e-07 - accuracy: 1.0000 - val_loss: 1.0589 - val_accuracy: 0.9127\n",
      "Epoch 149/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 4.0442e-07 - accuracy: 1.0000 - val_loss: 1.0612 - val_accuracy: 0.9127\n",
      "Epoch 150/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.9347e-07 - accuracy: 1.0000 - val_loss: 1.0640 - val_accuracy: 0.9127\n",
      "Epoch 151/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.8136e-07 - accuracy: 1.0000 - val_loss: 1.0665 - val_accuracy: 0.9127\n",
      "Epoch 152/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.7033e-07 - accuracy: 1.0000 - val_loss: 1.0690 - val_accuracy: 0.9127\n",
      "Epoch 153/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.5810e-07 - accuracy: 1.0000 - val_loss: 1.0715 - val_accuracy: 0.9127\n",
      "Epoch 154/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.4739e-07 - accuracy: 1.0000 - val_loss: 1.0740 - val_accuracy: 0.9127\n",
      "Epoch 155/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.3732e-07 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.9127\n",
      "Epoch 156/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.2673e-07 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.9127\n",
      "Epoch 157/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.1762e-07 - accuracy: 1.0000 - val_loss: 1.0815 - val_accuracy: 0.9127\n",
      "Epoch 158/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 3.0823e-07 - accuracy: 1.0000 - val_loss: 1.0841 - val_accuracy: 0.9127\n",
      "Epoch 159/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.9932e-07 - accuracy: 1.0000 - val_loss: 1.0864 - val_accuracy: 0.9127\n",
      "Epoch 160/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.9041e-07 - accuracy: 1.0000 - val_loss: 1.0890 - val_accuracy: 0.9127\n",
      "Epoch 161/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.8210e-07 - accuracy: 1.0000 - val_loss: 1.0914 - val_accuracy: 0.9127\n",
      "Epoch 162/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.7350e-07 - accuracy: 1.0000 - val_loss: 1.0939 - val_accuracy: 0.9127\n",
      "Epoch 163/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.6615e-07 - accuracy: 1.0000 - val_loss: 1.0964 - val_accuracy: 0.9127\n",
      "Epoch 164/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.5772e-07 - accuracy: 1.0000 - val_loss: 1.0989 - val_accuracy: 0.9127\n",
      "Epoch 165/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.5109e-07 - accuracy: 1.0000 - val_loss: 1.1013 - val_accuracy: 0.9127\n",
      "Epoch 166/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.4305e-07 - accuracy: 1.0000 - val_loss: 1.1039 - val_accuracy: 0.9127\n",
      "Epoch 167/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.3554e-07 - accuracy: 1.0000 - val_loss: 1.1063 - val_accuracy: 0.9127\n",
      "Epoch 168/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.2847e-07 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.9127\n",
      "Epoch 169/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 2.2103e-07 - accuracy: 1.0000 - val_loss: 1.1106 - val_accuracy: 0.9127\n",
      "Epoch 170/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.1428e-07 - accuracy: 1.0000 - val_loss: 1.1131 - val_accuracy: 0.9127\n",
      "Epoch 171/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.0765e-07 - accuracy: 1.0000 - val_loss: 1.1149 - val_accuracy: 0.9127\n",
      "Epoch 172/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.0177e-07 - accuracy: 1.0000 - val_loss: 1.1171 - val_accuracy: 0.9127\n",
      "Epoch 173/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.9514e-07 - accuracy: 1.0000 - val_loss: 1.1198 - val_accuracy: 0.9127\n",
      "Epoch 174/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.8846e-07 - accuracy: 1.0000 - val_loss: 1.1220 - val_accuracy: 0.9127\n",
      "Epoch 175/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.8335e-07 - accuracy: 1.0000 - val_loss: 1.1245 - val_accuracy: 0.9127\n",
      "Epoch 176/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.7839e-07 - accuracy: 1.0000 - val_loss: 1.1266 - val_accuracy: 0.9127\n",
      "Epoch 177/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.7340e-07 - accuracy: 1.0000 - val_loss: 1.1291 - val_accuracy: 0.9127\n",
      "Epoch 178/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.6832e-07 - accuracy: 1.0000 - val_loss: 1.1314 - val_accuracy: 0.9127\n",
      "Epoch 179/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.6297e-07 - accuracy: 1.0000 - val_loss: 1.1336 - val_accuracy: 0.9127\n",
      "Epoch 180/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.5817e-07 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.9127\n",
      "Epoch 181/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 1.5346e-07 - accuracy: 1.0000 - val_loss: 1.1382 - val_accuracy: 0.9127\n",
      "Epoch 182/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.4918e-07 - accuracy: 1.0000 - val_loss: 1.1403 - val_accuracy: 0.9127\n",
      "Epoch 183/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.4479e-07 - accuracy: 1.0000 - val_loss: 1.1425 - val_accuracy: 0.9127\n",
      "Epoch 184/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.4063e-07 - accuracy: 1.0000 - val_loss: 1.1447 - val_accuracy: 0.9127\n",
      "Epoch 185/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.3631e-07 - accuracy: 1.0000 - val_loss: 1.1475 - val_accuracy: 0.9127\n",
      "Epoch 186/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.3256e-07 - accuracy: 1.0000 - val_loss: 1.1496 - val_accuracy: 0.9127\n",
      "Epoch 187/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.2856e-07 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.9127\n",
      "Epoch 188/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.2500e-07 - accuracy: 1.0000 - val_loss: 1.1549 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.2109e-07 - accuracy: 1.0000 - val_loss: 1.1571 - val_accuracy: 0.9127\n",
      "Epoch 190/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.1757e-07 - accuracy: 1.0000 - val_loss: 1.1595 - val_accuracy: 0.9127\n",
      "Epoch 191/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.1429e-07 - accuracy: 1.0000 - val_loss: 1.1618 - val_accuracy: 0.9127\n",
      "Epoch 192/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.1062e-07 - accuracy: 1.0000 - val_loss: 1.1645 - val_accuracy: 0.9127\n",
      "Epoch 193/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.0778e-07 - accuracy: 1.0000 - val_loss: 1.1669 - val_accuracy: 0.9127\n",
      "Epoch 194/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.0418e-07 - accuracy: 1.0000 - val_loss: 1.1694 - val_accuracy: 0.9127\n",
      "Epoch 195/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.0151e-07 - accuracy: 1.0000 - val_loss: 1.1718 - val_accuracy: 0.9127\n",
      "Epoch 196/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 9.8868e-08 - accuracy: 1.0000 - val_loss: 1.1742 - val_accuracy: 0.9127\n",
      "Epoch 197/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 9.5791e-08 - accuracy: 1.0000 - val_loss: 1.1766 - val_accuracy: 0.9127\n",
      "Epoch 198/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 9.3273e-08 - accuracy: 1.0000 - val_loss: 1.1790 - val_accuracy: 0.9127\n",
      "Epoch 199/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 9.0756e-08 - accuracy: 1.0000 - val_loss: 1.1814 - val_accuracy: 0.9127\n",
      "Epoch 200/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 8.8038e-08 - accuracy: 1.0000 - val_loss: 1.1838 - val_accuracy: 0.9127\n",
      "Epoch 201/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 8.5440e-08 - accuracy: 1.0000 - val_loss: 1.1858 - val_accuracy: 0.9127\n",
      "Epoch 202/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 8.2883e-08 - accuracy: 1.0000 - val_loss: 1.1886 - val_accuracy: 0.9127\n",
      "Epoch 203/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 8.0605e-08 - accuracy: 1.0000 - val_loss: 1.1908 - val_accuracy: 0.9127\n",
      "Epoch 204/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.8327e-08 - accuracy: 1.0000 - val_loss: 1.1933 - val_accuracy: 0.9127\n",
      "Epoch 205/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.6409e-08 - accuracy: 1.0000 - val_loss: 1.1954 - val_accuracy: 0.9127\n",
      "Epoch 206/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.3931e-08 - accuracy: 1.0000 - val_loss: 1.1979 - val_accuracy: 0.9127\n",
      "Epoch 207/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.2053e-08 - accuracy: 1.0000 - val_loss: 1.2003 - val_accuracy: 0.9127\n",
      "Epoch 208/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.0055e-08 - accuracy: 1.0000 - val_loss: 1.2026 - val_accuracy: 0.9127\n",
      "Epoch 209/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.8177e-08 - accuracy: 1.0000 - val_loss: 1.2050 - val_accuracy: 0.9127\n",
      "Epoch 210/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.5979e-08 - accuracy: 1.0000 - val_loss: 1.2074 - val_accuracy: 0.9127\n",
      "Epoch 211/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.3861e-08 - accuracy: 1.0000 - val_loss: 1.2096 - val_accuracy: 0.9127\n",
      "Epoch 212/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.2142e-08 - accuracy: 1.0000 - val_loss: 1.2120 - val_accuracy: 0.9127\n",
      "Epoch 213/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 6.0064e-08 - accuracy: 1.0000 - val_loss: 1.2143 - val_accuracy: 0.9127\n",
      "Epoch 214/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.8346e-08 - accuracy: 1.0000 - val_loss: 1.2166 - val_accuracy: 0.9127\n",
      "Epoch 215/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.6507e-08 - accuracy: 1.0000 - val_loss: 1.2191 - val_accuracy: 0.9127\n",
      "Epoch 216/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.4709e-08 - accuracy: 1.0000 - val_loss: 1.2214 - val_accuracy: 0.9127\n",
      "Epoch 217/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.3630e-08 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.9127\n",
      "Epoch 218/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.1992e-08 - accuracy: 1.0000 - val_loss: 1.2261 - val_accuracy: 0.9127\n",
      "Epoch 219/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.0753e-08 - accuracy: 1.0000 - val_loss: 1.2286 - val_accuracy: 0.9127\n",
      "Epoch 220/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.9554e-08 - accuracy: 1.0000 - val_loss: 1.2310 - val_accuracy: 0.9127\n",
      "Epoch 221/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.8155e-08 - accuracy: 1.0000 - val_loss: 1.2333 - val_accuracy: 0.9127\n",
      "Epoch 222/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.6597e-08 - accuracy: 1.0000 - val_loss: 1.2354 - val_accuracy: 0.9127\n",
      "Epoch 223/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.5118e-08 - accuracy: 1.0000 - val_loss: 1.2379 - val_accuracy: 0.9127\n",
      "Epoch 224/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.4039e-08 - accuracy: 1.0000 - val_loss: 1.2402 - val_accuracy: 0.9127\n",
      "Epoch 225/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.2760e-08 - accuracy: 1.0000 - val_loss: 1.2425 - val_accuracy: 0.9127\n",
      "Epoch 226/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.0962e-08 - accuracy: 1.0000 - val_loss: 1.2448 - val_accuracy: 0.9157\n",
      "Epoch 227/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.9643e-08 - accuracy: 1.0000 - val_loss: 1.2472 - val_accuracy: 0.9127\n",
      "Epoch 228/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.8804e-08 - accuracy: 1.0000 - val_loss: 1.2495 - val_accuracy: 0.9127\n",
      "Epoch 229/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.7725e-08 - accuracy: 1.0000 - val_loss: 1.2520 - val_accuracy: 0.9127\n",
      "Epoch 230/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.6966e-08 - accuracy: 1.0000 - val_loss: 1.2544 - val_accuracy: 0.9157\n",
      "Epoch 231/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.5567e-08 - accuracy: 1.0000 - val_loss: 1.2567 - val_accuracy: 0.9157\n",
      "Epoch 232/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.4768e-08 - accuracy: 1.0000 - val_loss: 1.2591 - val_accuracy: 0.9157\n",
      "Epoch 233/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.3649e-08 - accuracy: 1.0000 - val_loss: 1.2615 - val_accuracy: 0.9127\n",
      "Epoch 234/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.2849e-08 - accuracy: 1.0000 - val_loss: 1.2638 - val_accuracy: 0.9157\n",
      "Epoch 235/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.2010e-08 - accuracy: 1.0000 - val_loss: 1.2660 - val_accuracy: 0.9157\n",
      "Epoch 236/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.1051e-08 - accuracy: 1.0000 - val_loss: 1.2686 - val_accuracy: 0.9127\n",
      "Epoch 237/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.0092e-08 - accuracy: 1.0000 - val_loss: 1.2709 - val_accuracy: 0.9127\n",
      "Epoch 238/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.8973e-08 - accuracy: 1.0000 - val_loss: 1.2734 - val_accuracy: 0.9127\n",
      "Epoch 239/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.8254e-08 - accuracy: 1.0000 - val_loss: 1.2758 - val_accuracy: 0.9127\n",
      "Epoch 240/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.7295e-08 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.9127\n",
      "Epoch 241/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.6815e-08 - accuracy: 1.0000 - val_loss: 1.2805 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.5856e-08 - accuracy: 1.0000 - val_loss: 1.2828 - val_accuracy: 0.9127\n",
      "Epoch 243/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.5097e-08 - accuracy: 1.0000 - val_loss: 1.2852 - val_accuracy: 0.9127\n",
      "Epoch 244/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.4297e-08 - accuracy: 1.0000 - val_loss: 1.2877 - val_accuracy: 0.9127\n",
      "Epoch 245/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 2.3258e-08 - accuracy: 1.0000 - val_loss: 1.2911 - val_accuracy: 0.9127\n",
      "Epoch 246/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.2499e-08 - accuracy: 1.0000 - val_loss: 1.2946 - val_accuracy: 0.9127\n",
      "Epoch 247/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.1860e-08 - accuracy: 1.0000 - val_loss: 1.2979 - val_accuracy: 0.9127\n",
      "Epoch 248/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.0981e-08 - accuracy: 1.0000 - val_loss: 1.3008 - val_accuracy: 0.9127\n",
      "Epoch 249/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.0341e-08 - accuracy: 1.0000 - val_loss: 1.3051 - val_accuracy: 0.9127\n",
      "Epoch 250/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.9582e-08 - accuracy: 1.0000 - val_loss: 1.3089 - val_accuracy: 0.9127\n",
      "Epoch 251/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.8862e-08 - accuracy: 1.0000 - val_loss: 1.3125 - val_accuracy: 0.9127\n",
      "Epoch 252/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.8223e-08 - accuracy: 1.0000 - val_loss: 1.3154 - val_accuracy: 0.9127\n",
      "Epoch 253/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.7384e-08 - accuracy: 1.0000 - val_loss: 1.3185 - val_accuracy: 0.9127\n",
      "Epoch 254/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.6704e-08 - accuracy: 1.0000 - val_loss: 1.3219 - val_accuracy: 0.9127\n",
      "Epoch 255/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.6265e-08 - accuracy: 1.0000 - val_loss: 1.3250 - val_accuracy: 0.9127\n",
      "Epoch 256/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5785e-08 - accuracy: 1.0000 - val_loss: 1.3282 - val_accuracy: 0.9127\n",
      "Epoch 257/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5386e-08 - accuracy: 1.0000 - val_loss: 1.3317 - val_accuracy: 0.9157\n",
      "Epoch 258/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.4626e-08 - accuracy: 1.0000 - val_loss: 1.3349 - val_accuracy: 0.9157\n",
      "Epoch 259/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.4107e-08 - accuracy: 1.0000 - val_loss: 1.3380 - val_accuracy: 0.9157\n",
      "Epoch 260/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.3787e-08 - accuracy: 1.0000 - val_loss: 1.3409 - val_accuracy: 0.9157\n",
      "Epoch 261/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.3148e-08 - accuracy: 1.0000 - val_loss: 1.3441 - val_accuracy: 0.9157\n",
      "Epoch 262/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.2628e-08 - accuracy: 1.0000 - val_loss: 1.3469 - val_accuracy: 0.9157\n",
      "Epoch 263/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.2069e-08 - accuracy: 1.0000 - val_loss: 1.3499 - val_accuracy: 0.9157\n",
      "Epoch 264/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.1869e-08 - accuracy: 1.0000 - val_loss: 1.3529 - val_accuracy: 0.9157\n",
      "Epoch 265/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.1270e-08 - accuracy: 1.0000 - val_loss: 1.3557 - val_accuracy: 0.9157\n",
      "Epoch 266/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.0990e-08 - accuracy: 1.0000 - val_loss: 1.3582 - val_accuracy: 0.9157\n",
      "Epoch 267/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.0630e-08 - accuracy: 1.0000 - val_loss: 1.3612 - val_accuracy: 0.9157\n",
      "Epoch 268/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.0230e-08 - accuracy: 1.0000 - val_loss: 1.3641 - val_accuracy: 0.9157\n",
      "Epoch 269/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 9.8708e-09 - accuracy: 1.0000 - val_loss: 1.3669 - val_accuracy: 0.9157\n",
      "Epoch 270/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 9.5511e-09 - accuracy: 1.0000 - val_loss: 1.3695 - val_accuracy: 0.9157\n",
      "Epoch 271/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 9.1515e-09 - accuracy: 1.0000 - val_loss: 1.3724 - val_accuracy: 0.9157\n",
      "Epoch 272/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 8.8718e-09 - accuracy: 1.0000 - val_loss: 1.3749 - val_accuracy: 0.9157\n",
      "Epoch 273/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 8.6320e-09 - accuracy: 1.0000 - val_loss: 1.3775 - val_accuracy: 0.9157\n",
      "Epoch 274/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 8.3522e-09 - accuracy: 1.0000 - val_loss: 1.3805 - val_accuracy: 0.9157\n",
      "Epoch 275/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.9926e-09 - accuracy: 1.0000 - val_loss: 1.3830 - val_accuracy: 0.9157\n",
      "Epoch 276/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 7.8727e-09 - accuracy: 1.0000 - val_loss: 1.3858 - val_accuracy: 0.9157\n",
      "Epoch 277/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 7.7528e-09 - accuracy: 1.0000 - val_loss: 1.3883 - val_accuracy: 0.9157\n",
      "Epoch 278/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.4731e-09 - accuracy: 1.0000 - val_loss: 1.3912 - val_accuracy: 0.9157\n",
      "Epoch 279/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.1134e-09 - accuracy: 1.0000 - val_loss: 1.3934 - val_accuracy: 0.9157\n",
      "Epoch 280/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.9935e-09 - accuracy: 1.0000 - val_loss: 1.3965 - val_accuracy: 0.9157\n",
      "Epoch 281/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.6738e-09 - accuracy: 1.0000 - val_loss: 1.3991 - val_accuracy: 0.9157\n",
      "Epoch 282/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.6338e-09 - accuracy: 1.0000 - val_loss: 1.4015 - val_accuracy: 0.9157\n",
      "Epoch 283/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.4340e-09 - accuracy: 1.0000 - val_loss: 1.4042 - val_accuracy: 0.9157\n",
      "Epoch 284/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.2742e-09 - accuracy: 1.0000 - val_loss: 1.4068 - val_accuracy: 0.9157\n",
      "Epoch 285/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.1143e-09 - accuracy: 1.0000 - val_loss: 1.4095 - val_accuracy: 0.9157\n",
      "Epoch 286/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.9145e-09 - accuracy: 1.0000 - val_loss: 1.4121 - val_accuracy: 0.9157\n",
      "Epoch 287/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.6348e-09 - accuracy: 1.0000 - val_loss: 1.4148 - val_accuracy: 0.9157\n",
      "Epoch 288/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.3950e-09 - accuracy: 1.0000 - val_loss: 1.4173 - val_accuracy: 0.9157\n",
      "Epoch 289/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.2351e-09 - accuracy: 1.0000 - val_loss: 1.4198 - val_accuracy: 0.9157\n",
      "Epoch 290/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.1552e-09 - accuracy: 1.0000 - val_loss: 1.4222 - val_accuracy: 0.9157\n",
      "Epoch 291/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.0753e-09 - accuracy: 1.0000 - val_loss: 1.4248 - val_accuracy: 0.9157\n",
      "Epoch 292/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.8355e-09 - accuracy: 1.0000 - val_loss: 1.4274 - val_accuracy: 0.9157\n",
      "Epoch 293/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.7156e-09 - accuracy: 1.0000 - val_loss: 1.4300 - val_accuracy: 0.9157\n",
      "Epoch 294/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.5158e-09 - accuracy: 1.0000 - val_loss: 1.4326 - val_accuracy: 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.2361e-09 - accuracy: 1.0000 - val_loss: 1.4351 - val_accuracy: 0.9157\n",
      "Epoch 296/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.0762e-09 - accuracy: 1.0000 - val_loss: 1.4375 - val_accuracy: 0.9157\n",
      "Epoch 297/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.7965e-09 - accuracy: 1.0000 - val_loss: 1.4400 - val_accuracy: 0.9157\n",
      "Epoch 298/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.7165e-09 - accuracy: 1.0000 - val_loss: 1.4425 - val_accuracy: 0.9157\n",
      "Epoch 299/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.5167e-09 - accuracy: 1.0000 - val_loss: 1.4448 - val_accuracy: 0.9157\n",
      "Epoch 300/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.3569e-09 - accuracy: 1.0000 - val_loss: 1.4471 - val_accuracy: 0.9157\n",
      "Epoch 301/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.2770e-09 - accuracy: 1.0000 - val_loss: 1.4495 - val_accuracy: 0.9157\n",
      "Epoch 302/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.1970e-09 - accuracy: 1.0000 - val_loss: 1.4518 - val_accuracy: 0.9157\n",
      "Epoch 303/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.0372e-09 - accuracy: 1.0000 - val_loss: 1.4542 - val_accuracy: 0.9157\n",
      "Epoch 304/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.9173e-09 - accuracy: 1.0000 - val_loss: 1.4563 - val_accuracy: 0.9157\n",
      "Epoch 305/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.8773e-09 - accuracy: 1.0000 - val_loss: 1.4585 - val_accuracy: 0.9157\n",
      "Epoch 306/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.8374e-09 - accuracy: 1.0000 - val_loss: 1.4610 - val_accuracy: 0.9157\n",
      "Epoch 307/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.7574e-09 - accuracy: 1.0000 - val_loss: 1.4633 - val_accuracy: 0.9157\n",
      "Epoch 308/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.5177e-09 - accuracy: 1.0000 - val_loss: 1.4655 - val_accuracy: 0.9157\n",
      "Epoch 309/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.4377e-09 - accuracy: 1.0000 - val_loss: 1.4676 - val_accuracy: 0.9157\n",
      "Epoch 310/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.3978e-09 - accuracy: 1.0000 - val_loss: 1.4699 - val_accuracy: 0.9157\n",
      "Epoch 311/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.2779e-09 - accuracy: 1.0000 - val_loss: 1.4722 - val_accuracy: 0.9157\n",
      "Epoch 312/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.2379e-09 - accuracy: 1.0000 - val_loss: 1.4744 - val_accuracy: 0.9157\n",
      "Epoch 313/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.1980e-09 - accuracy: 1.0000 - val_loss: 1.4765 - val_accuracy: 0.9157\n",
      "Epoch 314/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.0781e-09 - accuracy: 1.0000 - val_loss: 1.4786 - val_accuracy: 0.9157\n",
      "Epoch 315/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.0381e-09 - accuracy: 1.0000 - val_loss: 1.4810 - val_accuracy: 0.9157\n",
      "Epoch 316/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.9981e-09 - accuracy: 1.0000 - val_loss: 1.4831 - val_accuracy: 0.9157\n",
      "Epoch 317/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.9182e-09 - accuracy: 1.0000 - val_loss: 1.4851 - val_accuracy: 0.9157\n",
      "Epoch 318/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.8783e-09 - accuracy: 1.0000 - val_loss: 1.4875 - val_accuracy: 0.9157\n",
      "Epoch 319/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.7584e-09 - accuracy: 1.0000 - val_loss: 1.4897 - val_accuracy: 0.9157\n",
      "Epoch 320/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.6385e-09 - accuracy: 1.0000 - val_loss: 1.4918 - val_accuracy: 0.9157\n",
      "Epoch 321/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5186e-09 - accuracy: 1.0000 - val_loss: 1.4937 - val_accuracy: 0.9157\n",
      "Epoch 322/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5186e-09 - accuracy: 1.0000 - val_loss: 1.4958 - val_accuracy: 0.9157\n",
      "Epoch 323/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5186e-09 - accuracy: 1.0000 - val_loss: 1.4978 - val_accuracy: 0.9157\n",
      "Epoch 324/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.3987e-09 - accuracy: 1.0000 - val_loss: 1.5000 - val_accuracy: 0.9157\n",
      "Epoch 325/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.4387e-09 - accuracy: 1.0000 - val_loss: 1.5021 - val_accuracy: 0.9157\n",
      "Epoch 326/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.3587e-09 - accuracy: 1.0000 - val_loss: 1.5042 - val_accuracy: 0.9157\n",
      "Epoch 327/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.3587e-09 - accuracy: 1.0000 - val_loss: 1.5062 - val_accuracy: 0.9157\n",
      "Epoch 328/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.2388e-09 - accuracy: 1.0000 - val_loss: 1.5084 - val_accuracy: 0.9157\n",
      "Epoch 329/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.1190e-09 - accuracy: 1.0000 - val_loss: 1.5103 - val_accuracy: 0.9157\n",
      "Epoch 330/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.1589e-09 - accuracy: 1.0000 - val_loss: 1.5122 - val_accuracy: 0.9157\n",
      "Epoch 331/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.1589e-09 - accuracy: 1.0000 - val_loss: 1.5143 - val_accuracy: 0.9157\n",
      "Epoch 332/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.0790e-09 - accuracy: 1.0000 - val_loss: 1.5163 - val_accuracy: 0.9157\n",
      "Epoch 333/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.0790e-09 - accuracy: 1.0000 - val_loss: 1.5183 - val_accuracy: 0.9157\n",
      "Epoch 334/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.0790e-09 - accuracy: 1.0000 - val_loss: 1.5203 - val_accuracy: 0.9157\n",
      "Epoch 335/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.0790e-09 - accuracy: 1.0000 - val_loss: 1.5223 - val_accuracy: 0.9157\n",
      "Epoch 336/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 9.9907e-10 - accuracy: 1.0000 - val_loss: 1.5244 - val_accuracy: 0.9157\n",
      "Epoch 337/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 9.9907e-10 - accuracy: 1.0000 - val_loss: 1.5264 - val_accuracy: 0.9157\n",
      "Epoch 338/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 9.5911e-10 - accuracy: 1.0000 - val_loss: 1.5284 - val_accuracy: 0.9157\n",
      "Epoch 339/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 9.1915e-10 - accuracy: 1.0000 - val_loss: 1.5304 - val_accuracy: 0.9157\n",
      "Epoch 340/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 8.7918e-10 - accuracy: 1.0000 - val_loss: 1.5324 - val_accuracy: 0.9157\n",
      "Epoch 341/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.5929e-10 - accuracy: 1.0000 - val_loss: 1.5343 - val_accuracy: 0.9157\n",
      "Epoch 342/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.5929e-10 - accuracy: 1.0000 - val_loss: 1.5363 - val_accuracy: 0.9157\n",
      "Epoch 343/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.1933e-10 - accuracy: 1.0000 - val_loss: 1.5383 - val_accuracy: 0.9157\n",
      "Epoch 344/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.7937e-10 - accuracy: 1.0000 - val_loss: 1.5400 - val_accuracy: 0.9157\n",
      "Epoch 345/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.7937e-10 - accuracy: 1.0000 - val_loss: 1.5419 - val_accuracy: 0.9157\n",
      "Epoch 346/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.3941e-10 - accuracy: 1.0000 - val_loss: 1.5436 - val_accuracy: 0.9157\n",
      "Epoch 347/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.3941e-10 - accuracy: 1.0000 - val_loss: 1.5455 - val_accuracy: 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 6.3941e-10 - accuracy: 1.0000 - val_loss: 1.5474 - val_accuracy: 0.9157\n",
      "Epoch 349/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.9944e-10 - accuracy: 1.0000 - val_loss: 1.5494 - val_accuracy: 0.9157\n",
      "Epoch 350/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.5948e-10 - accuracy: 1.0000 - val_loss: 1.5512 - val_accuracy: 0.9157\n",
      "Epoch 351/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.5948e-10 - accuracy: 1.0000 - val_loss: 1.5531 - val_accuracy: 0.9157\n",
      "Epoch 352/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.5948e-10 - accuracy: 1.0000 - val_loss: 1.5549 - val_accuracy: 0.9157\n",
      "Epoch 353/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 5.5948e-10 - accuracy: 1.0000 - val_loss: 1.5569 - val_accuracy: 0.9157\n",
      "Epoch 354/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.5948e-10 - accuracy: 1.0000 - val_loss: 1.5589 - val_accuracy: 0.9157\n",
      "Epoch 355/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 5.5948e-10 - accuracy: 1.0000 - val_loss: 1.5608 - val_accuracy: 0.9157\n",
      "Epoch 356/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.7955e-10 - accuracy: 1.0000 - val_loss: 1.5627 - val_accuracy: 0.9157\n",
      "Epoch 357/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.7955e-10 - accuracy: 1.0000 - val_loss: 1.5646 - val_accuracy: 0.9157\n",
      "Epoch 358/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.7955e-10 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.9157\n",
      "Epoch 359/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.7955e-10 - accuracy: 1.0000 - val_loss: 1.5685 - val_accuracy: 0.9157\n",
      "Epoch 360/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.3959e-10 - accuracy: 1.0000 - val_loss: 1.5704 - val_accuracy: 0.9157\n",
      "Epoch 361/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.3959e-10 - accuracy: 1.0000 - val_loss: 1.5723 - val_accuracy: 0.9157\n",
      "Epoch 362/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.3959e-10 - accuracy: 1.0000 - val_loss: 1.5742 - val_accuracy: 0.9157\n",
      "Epoch 363/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 4.3959e-10 - accuracy: 1.0000 - val_loss: 1.5761 - val_accuracy: 0.9157\n",
      "Epoch 364/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.9963e-10 - accuracy: 1.0000 - val_loss: 1.5780 - val_accuracy: 0.9157\n",
      "Epoch 365/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.5967e-10 - accuracy: 1.0000 - val_loss: 1.5799 - val_accuracy: 0.9157\n",
      "Epoch 366/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.1970e-10 - accuracy: 1.0000 - val_loss: 1.5816 - val_accuracy: 0.9157\n",
      "Epoch 367/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.1970e-10 - accuracy: 1.0000 - val_loss: 1.5835 - val_accuracy: 0.9127\n",
      "Epoch 368/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.7974e-10 - accuracy: 1.0000 - val_loss: 1.5852 - val_accuracy: 0.9127\n",
      "Epoch 369/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.1970e-10 - accuracy: 1.0000 - val_loss: 1.5869 - val_accuracy: 0.9127\n",
      "Epoch 370/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 2.3978e-10 - accuracy: 1.0000 - val_loss: 1.5886 - val_accuracy: 0.9127\n",
      "Epoch 371/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 2.3978e-10 - accuracy: 1.0000 - val_loss: 1.5904 - val_accuracy: 0.9127\n",
      "Epoch 372/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.9981e-10 - accuracy: 1.0000 - val_loss: 1.5921 - val_accuracy: 0.9127\n",
      "Epoch 373/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.9981e-10 - accuracy: 1.0000 - val_loss: 1.5937 - val_accuracy: 0.9127\n",
      "Epoch 374/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.5955 - val_accuracy: 0.9127\n",
      "Epoch 375/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.5972 - val_accuracy: 0.9127\n",
      "Epoch 376/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.5989 - val_accuracy: 0.9127\n",
      "Epoch 377/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6005 - val_accuracy: 0.9127\n",
      "Epoch 378/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6022 - val_accuracy: 0.9127\n",
      "Epoch 379/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6040 - val_accuracy: 0.9127\n",
      "Epoch 380/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6058 - val_accuracy: 0.9127\n",
      "Epoch 381/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6075 - val_accuracy: 0.9127\n",
      "Epoch 382/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6094 - val_accuracy: 0.9127\n",
      "Epoch 383/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6111 - val_accuracy: 0.9127\n",
      "Epoch 384/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6128 - val_accuracy: 0.9127\n",
      "Epoch 385/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6145 - val_accuracy: 0.9127\n",
      "Epoch 386/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6163 - val_accuracy: 0.9127\n",
      "Epoch 387/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6180 - val_accuracy: 0.9127\n",
      "Epoch 388/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.5985e-10 - accuracy: 1.0000 - val_loss: 1.6198 - val_accuracy: 0.9127\n",
      "Epoch 389/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.1989e-10 - accuracy: 1.0000 - val_loss: 1.6217 - val_accuracy: 0.9127\n",
      "Epoch 390/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.1989e-10 - accuracy: 1.0000 - val_loss: 1.6236 - val_accuracy: 0.9127\n",
      "Epoch 391/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 1.1989e-10 - accuracy: 1.0000 - val_loss: 1.6254 - val_accuracy: 0.9127\n",
      "Epoch 392/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 7.9926e-11 - accuracy: 1.0000 - val_loss: 1.6272 - val_accuracy: 0.9127\n",
      "Epoch 393/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.9926e-11 - accuracy: 1.0000 - val_loss: 1.6290 - val_accuracy: 0.9127\n",
      "Epoch 394/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.9926e-11 - accuracy: 1.0000 - val_loss: 1.6308 - val_accuracy: 0.9127\n",
      "Epoch 395/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 7.9926e-11 - accuracy: 1.0000 - val_loss: 1.6327 - val_accuracy: 0.9127\n",
      "Epoch 396/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 3.9963e-11 - accuracy: 1.0000 - val_loss: 1.6345 - val_accuracy: 0.9127\n",
      "Epoch 397/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.9963e-11 - accuracy: 1.0000 - val_loss: 1.6363 - val_accuracy: 0.9127\n",
      "Epoch 398/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.9963e-11 - accuracy: 1.0000 - val_loss: 1.6378 - val_accuracy: 0.9127\n",
      "Epoch 399/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.9963e-11 - accuracy: 1.0000 - val_loss: 1.6398 - val_accuracy: 0.9127\n",
      "Epoch 400/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 3.9963e-11 - accuracy: 1.0000 - val_loss: 1.6416 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6433 - val_accuracy: 0.9127\n",
      "Epoch 402/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6450 - val_accuracy: 0.9127\n",
      "Epoch 403/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6468 - val_accuracy: 0.9127\n",
      "Epoch 404/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6485 - val_accuracy: 0.9127\n",
      "Epoch 405/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6502 - val_accuracy: 0.9127\n",
      "Epoch 406/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6521 - val_accuracy: 0.9127\n",
      "Epoch 407/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6537 - val_accuracy: 0.9127\n",
      "Epoch 408/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6554 - val_accuracy: 0.9127\n",
      "Epoch 409/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6572 - val_accuracy: 0.9127\n",
      "Epoch 410/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6589 - val_accuracy: 0.9127\n",
      "Epoch 411/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6606 - val_accuracy: 0.9127\n",
      "Epoch 412/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6624 - val_accuracy: 0.9127\n",
      "Epoch 413/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6642 - val_accuracy: 0.9127\n",
      "Epoch 414/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6658 - val_accuracy: 0.9127\n",
      "Epoch 415/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6677 - val_accuracy: 0.9127\n",
      "Epoch 416/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6696 - val_accuracy: 0.9127\n",
      "Epoch 417/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6713 - val_accuracy: 0.9127\n",
      "Epoch 418/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6731 - val_accuracy: 0.9127\n",
      "Epoch 419/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6748 - val_accuracy: 0.9127\n",
      "Epoch 420/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6765 - val_accuracy: 0.9127\n",
      "Epoch 421/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6784 - val_accuracy: 0.9127\n",
      "Epoch 422/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6801 - val_accuracy: 0.9127\n",
      "Epoch 423/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6819 - val_accuracy: 0.9127\n",
      "Epoch 424/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6836 - val_accuracy: 0.9127\n",
      "Epoch 425/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6854 - val_accuracy: 0.9127\n",
      "Epoch 426/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6873 - val_accuracy: 0.9127\n",
      "Epoch 427/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6890 - val_accuracy: 0.9127\n",
      "Epoch 428/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6908 - val_accuracy: 0.9127\n",
      "Epoch 429/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6925 - val_accuracy: 0.9127\n",
      "Epoch 430/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6943 - val_accuracy: 0.9127\n",
      "Epoch 431/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6962 - val_accuracy: 0.9127\n",
      "Epoch 432/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6979 - val_accuracy: 0.9127\n",
      "Epoch 433/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.6998 - val_accuracy: 0.9127\n",
      "Epoch 434/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7016 - val_accuracy: 0.9127\n",
      "Epoch 435/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7033 - val_accuracy: 0.9127\n",
      "Epoch 436/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7051 - val_accuracy: 0.9127\n",
      "Epoch 437/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7069 - val_accuracy: 0.9127\n",
      "Epoch 438/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7087 - val_accuracy: 0.9127\n",
      "Epoch 439/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7104 - val_accuracy: 0.9127\n",
      "Epoch 440/500\n",
      "2983/2983 [==============================] - 34s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7122 - val_accuracy: 0.9127\n",
      "Epoch 441/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.9127\n",
      "Epoch 442/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7158 - val_accuracy: 0.9127\n",
      "Epoch 443/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7175 - val_accuracy: 0.9127\n",
      "Epoch 444/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7194 - val_accuracy: 0.9127\n",
      "Epoch 445/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7211 - val_accuracy: 0.9127\n",
      "Epoch 446/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7230 - val_accuracy: 0.9127\n",
      "Epoch 447/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7245 - val_accuracy: 0.9127\n",
      "Epoch 448/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7265 - val_accuracy: 0.9127\n",
      "Epoch 449/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7282 - val_accuracy: 0.9127\n",
      "Epoch 450/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7299 - val_accuracy: 0.9127\n",
      "Epoch 451/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7318 - val_accuracy: 0.9127\n",
      "Epoch 452/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7335 - val_accuracy: 0.9127\n",
      "Epoch 453/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7352 - val_accuracy: 0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7371 - val_accuracy: 0.9127\n",
      "Epoch 455/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7388 - val_accuracy: 0.9127\n",
      "Epoch 456/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7405 - val_accuracy: 0.9127\n",
      "Epoch 457/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7424 - val_accuracy: 0.9127\n",
      "Epoch 458/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7442 - val_accuracy: 0.9127\n",
      "Epoch 459/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7460 - val_accuracy: 0.9127\n",
      "Epoch 460/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7478 - val_accuracy: 0.9127\n",
      "Epoch 461/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7494 - val_accuracy: 0.9127\n",
      "Epoch 462/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7510 - val_accuracy: 0.9127\n",
      "Epoch 463/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7529 - val_accuracy: 0.9127\n",
      "Epoch 464/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7546 - val_accuracy: 0.9127\n",
      "Epoch 465/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7564 - val_accuracy: 0.9127\n",
      "Epoch 466/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7582 - val_accuracy: 0.9127\n",
      "Epoch 467/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7598 - val_accuracy: 0.9127\n",
      "Epoch 468/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7616 - val_accuracy: 0.9127\n",
      "Epoch 469/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7632 - val_accuracy: 0.9127\n",
      "Epoch 470/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7651 - val_accuracy: 0.9127\n",
      "Epoch 471/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7667 - val_accuracy: 0.9127\n",
      "Epoch 472/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7685 - val_accuracy: 0.9127\n",
      "Epoch 473/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7701 - val_accuracy: 0.9127\n",
      "Epoch 474/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7719 - val_accuracy: 0.9127\n",
      "Epoch 475/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7735 - val_accuracy: 0.9127\n",
      "Epoch 476/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7753 - val_accuracy: 0.9127\n",
      "Epoch 477/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7771 - val_accuracy: 0.9127\n",
      "Epoch 478/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7785 - val_accuracy: 0.9127\n",
      "Epoch 479/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7803 - val_accuracy: 0.9127\n",
      "Epoch 480/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7820 - val_accuracy: 0.9127\n",
      "Epoch 481/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7836 - val_accuracy: 0.9127\n",
      "Epoch 482/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7854 - val_accuracy: 0.9127\n",
      "Epoch 483/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7870 - val_accuracy: 0.9127\n",
      "Epoch 484/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7887 - val_accuracy: 0.9127\n",
      "Epoch 485/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7904 - val_accuracy: 0.9127\n",
      "Epoch 486/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7920 - val_accuracy: 0.9127\n",
      "Epoch 487/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7936 - val_accuracy: 0.9127\n",
      "Epoch 488/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7952 - val_accuracy: 0.9127\n",
      "Epoch 489/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7969 - val_accuracy: 0.9127\n",
      "Epoch 490/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.7984 - val_accuracy: 0.9127\n",
      "Epoch 491/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8001 - val_accuracy: 0.9127\n",
      "Epoch 492/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8018 - val_accuracy: 0.9127\n",
      "Epoch 493/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8035 - val_accuracy: 0.9127\n",
      "Epoch 494/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8051 - val_accuracy: 0.9127\n",
      "Epoch 495/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8067 - val_accuracy: 0.9127\n",
      "Epoch 496/500\n",
      "2983/2983 [==============================] - 33s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8083 - val_accuracy: 0.9127\n",
      "Epoch 497/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8100 - val_accuracy: 0.9127\n",
      "Epoch 498/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8116 - val_accuracy: 0.9127\n",
      "Epoch 499/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8133 - val_accuracy: 0.9127\n",
      "Epoch 500/500\n",
      "2983/2983 [==============================] - 32s 11ms/sample - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.8148 - val_accuracy: 0.9127\n"
     ]
    }
   ],
   "source": [
    "#def binary_classification_model():\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(128,(3,3),padding = 'same',input_shape=(X.shape[1:]),kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape=(X.shape[1:]),kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape=(X.shape[1:]),kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape=(X.shape[1:]),kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',kernel_initializer = 'he_normal'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\")) # added a hidden layer\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\")) # added a new hidden layer\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\")) # added a new hidden layer\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\")) # added a new hidden layer\n",
    "\n",
    "model.add(Dense(2))\n",
    "#model.add(Dense(4))\n",
    "model.add(Activation('softmax')) # chaging from sigmoid to softmax to include more classes\n",
    "\n",
    "########################\n",
    "#class_weight = {0: 1., 1: 15.}\n",
    "#class_weight = {0: 5, 1: 10., 2: 1., 3:5.}\n",
    "########################\n",
    "\n",
    "#filepath=\"weights.best.hdf5\"\n",
    "ada = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss =\"categorical_crossentropy\", optimizer = 'adam', metrics = [\"accuracy\"])\n",
    "y_train=to_categorical(y, num_classes=2)\n",
    "\n",
    "model.summary()\n",
    "#lr_model_history=model.fit(X,y_train,batch_size=64,epochs= 10,validation_split=0.1,class_weight=class_weight)\n",
    "lr_model_history=model.fit(X,y_train,batch_size=64,epochs= 500,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Failed to create a NewWriteableFile: //ibs9010/current_data/Data_Keshav/image/Classification_model/NeuronClassifierModels/BinaryClassifier_bigtile_500epoch_3slicetrialdata/variables\\variables_temp_eaa546ff2da74e2bb85058d4573ec632/part-00000-of-00001.data-00000-of-00001.tempstate6903503056362727234 : The system cannot find the path specified.\r\n; No such process [Op:SaveV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-f591dc9d91e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//ibs9010/current_data/Data_Keshav/image/Classification_model/NeuronClassifierModels/BinaryClassifier_bigtile_500epoch_3slicetrialdata/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \"\"\"\n\u001b[0;32m   1007\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1008\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    113\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n\u001b[1;32m--> 115\u001b[1;33m                           signatures, options)\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(model, filepath, overwrite, include_optimizer, signatures, options)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m# we use the default replica context here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mdistribution_strategy_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_default_replica_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m       \u001b[0msave_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\save.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[1;31m# SavedModel proto itself.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m   \u001b[0mutils_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_or_create_variables_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 916\u001b[1;33m   \u001b[0mobject_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutils_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variables_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    917\u001b[0m   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,\n\u001b[0;32m    918\u001b[0m                                               export_dir)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[1;32m-> 1168\u001b[1;33m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[0;32m   1169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[0;32m   1114\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1115\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0msharded_saves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[0;32m   1705\u001b[0m         return save_v2_eager_fallback(\n\u001b[0;32m   1706\u001b[0m             \u001b[0mprefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1707\u001b[1;33m             ctx=_ctx)\n\u001b[0m\u001b[0;32m   1708\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1709\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[1;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[0;32m   1727\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"dtypes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1728\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[1;32m-> 1729\u001b[1;33m                              ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m   1730\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Failed to create a NewWriteableFile: //ibs9010/current_data/Data_Keshav/image/Classification_model/NeuronClassifierModels/BinaryClassifier_bigtile_500epoch_3slicetrialdata/variables\\variables_temp_eaa546ff2da74e2bb85058d4573ec632/part-00000-of-00001.data-00000-of-00001.tempstate6903503056362727234 : The system cannot find the path specified.\r\n; No such process [Op:SaveV2]"
     ]
    }
   ],
   "source": [
    "model.save(\"//ibs9010/current_data/Data_Keshav/image/Classification_model/NeuronClassifierModels/BinaryClassifier_bigtile_500epoch_3slicetrialdata/\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6sAAAFPCAYAAACrqFg4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdebzd073/8dcnERIRmURNJUSQIjXEVMRUMbSqhqrr6q0OWtRVftrKxUW0VO9VdePSFqV05HJRWq6qMYZWUhokIUQIaWWSyHBOZFi/P9beOefsM+6Tc7L3SV7Px+M8vmd/1/e7vuucEn3ns75rRUoJSZIkSZKqSbdKD0CSJEmSpFKGVUmSJElS1TGsSpIkSZKqjmFVkiRJklR1DKuSJEmSpKpjWJUkSZIkVZ31Kj2Addkmm2ySBg8eXOlhSJIkSVJFTJgwYU5KaVBTbYbVCho8eDDjx4+v9DAkSZIkqSIi4q3m2pwGLEmSJEmqOoZVSZIkSVLVMaxKkiRJkqqOYVWSJEmSVHUqHlYj4sSIuC4inoqIDyIiRcQv29nXVhFxS0TMjIilETE9Iq6NiP4t3POxiLgzImZFRG1EvBoRYyKiVwv3fCIi/hAR8yJiSURMjIhzI6J7e8YtSZIkSWqoGlYDvhj4OLAIeAfYqT2dRMQQ4BlgU+A+YAqwN/BN4MiI2D+lNLfknn2AR4EewF3ADOBQ4BLgsIg4LKW0tOSeY4G7gVrgDmAecAzwI2B/4HPtGb8kSZIkqU7FK6vAecAOwMbAmavRzw3koHpOSumzKaXRKaVDySFyR+CK+hcXqqC3AhsCJ6aUTkkpXQDsQw6j+xfGVv+ejYGbgBXAwSmlr6SUvg3sBjwLnBgRJ6/GzyBJkiRJogrCakrpsZTS1JRSam8fEbEdMAqYDlxf0nwpsBj4QkT0rnf+IGAY8GRK6Xf1xrMS+E7h4xkREfXuOREYBPw2pTS+3j215AoxrF7gliRJkiRRBWG1gxxaOD5cCJurpJQWAk+TK6j7NnHPQ6WdpZSmAa8B2wDbteUe4ElgCfCJiNig3B9AkiRJklSnGt5Z7Qg7Fo6vNdM+lVx53QH4Uxn37FD4eqO1e1JKyyPiTWBncsCd3NbBq5O99x488ACsXNn6tZIkSdLa6OMfh733rvQoyrK2hNW+heOCZtqL5/tV4J4GIuJrwNcAtt566+YuU0d56SU46ih4991Kj0SSJEmqnAsuMKxWqeJ7p+W8F9sp96SUbgRuBBgxYkS739NVwTvvwFtvwSc+AVOmwOLFMGJEbqupgUMOgQ02gKefhm22qexYJUmSpErZaKNKj6Bsa0tYLVY0+zbTvnHJdWvyHnWmb38bfvtb2GqrHFwBvvhFuP56eOEFmDsX7r03h1lJkiRJXcbaElZfLRx3aKZ9aOFY/13T9t4zonDPhPoXR8R6wLbAcmBa60NWh3j7bRg8GIYNgzPPhCVL4IorYIcdYL3CP94GVUmSJKnLWVvC6mOF46iI6FZ/ReCI6EPeM7UGeK7ePY8CFwFHAt+v31lhK5wdgLdoGDwfBf65cM9vSsYwkrzi8JMppaWr+wOpBffck6f7nnpqXjxpv/3g17+ua//jH+G++2DzzWHoUBg0qHJjlSRJktQuXWrrmojoERE7RcSQ+udTSm8ADwODgW+U3DYG6A3cnlJaXO/8E+QVe0dGxGfqPaMb8IPCx5+U7P96FzAHODkiRtS7pyfwvcLHH7fzx1PRP/4B558PCxfWnbv9drjjjvz9BRfA975Xd+1mmzW8/5hj4C9/gcces6oqSZIkdVEVr6xGxGeBzxY+FlPHfhHx88L3c1JK3yp8vyU5YL5FDqb1nQU8A4yNiMMK1+0DHEKeyntR/YtTSisi4kvkauldEXEX8DZwGHmq79PAj0ru+SAiTieH1scj4rfAPOAz5G1t7gLuKP+3oAb+7//gmmtg6VL47/+GN96A00+H/v1hn31g6lTo3RsWLcoV1o98pOH9xxwD//7v8MEHhlVJkiSpi6p4WAV2A75Ycm67whfkYPotWpFSeqNQ7bycPE33aODvwFhgTEppXhP3/Dki9iJXX0cBfQrPuxy4qqnpvCmleyPiIHL4PQHoCbwO/D9gbEklVu0xa1Y+3nADHH54rqp++GGe8nv55blt8WJ4tfDacWlldfhw+OhHYcYMw6okSZLURVU8rKaULgMua+O106nbHqap9hnAl8p8/iTgc2Xe8zQ5DKszzJqVt5vZYgv4bKHo/q1vwXXXwa231l03fnw+llZWI+Ckk/J7rB/72JoZsyRJkqQO1aXeWdU64r33crV0/Pi8Lc1VV+WK6qhRuX3bbfNxQmFB5tLKKsCVV8JLL0E3/xGXJEmSuiL/n7yqz6xZsOmmMGAAfP7zeUGlXr3g+ONz+xcLs8aLldWmwur668PAgWtmvJIkSZI6nGFV1WfWrMZTewFOPhn+4z/g3HPzVN+XX87HTTZZ82OUJEmS1KkMq6q8f/5nGDu27nOxslqqZ0/49rehb99cTV22LO+hul7FX72WJEmS1MEMq6q8e++F0aPz6r0pNR9W69tqq3xsqgIrSZIkqcszrKqyamthyRKoqYGLLoIFC3LFtK1htan3VSVJkiR1eYZVVdb77+fjFlvAL34Bf/1r/mxlVZIkSVqnGVZVWfPm5ePnClvdPvhgPlpZlSRJktZphlVVVjGsHnRQXtn34YfzZyurkiRJ0jrNsKrKKobVrbeGoUNh4sT8ubUQamVVkiRJWqsZVrVmLVgAf/xj3ediWB0wAHbbre58a3un7r03nH02HHFEx49RkiRJUsUZVrVmfetbMGoU/Pa3+XNTYXXgwNb3Tu3ZE667Lu+zKkmSJGmtY1jVmrNkCdxxR3439fTTYerUvBpw9+6w8cZ1YbW191UlSZIkrfUMq1pz7r0XFi6E22+H5cvh+utzZbV//xxgDauSJEmSCgyrWnN+/nPYZhs45ZS8mNKbb+awOmBAbt9ss7yw0uabV3SYkiRJkiqvlRcDpQ5SUwOPPAIXXADduuXQOn16DqfFsBoB99zje6iSJEmSDKtaQ6ZPh5Rgl13y58GD4amnoEePhtvU7LdfJUYnSZIkqco4DVhrxrRp+bjddvk4eHDexmbatLrKqiRJkiQVGFa1Zrz5Zj7WD6uQVwM2rEqSJEkqYVjVmjFtGmy4Yd1Kv9tsU9fWv39lxiRJkiSpahlWtWZMmwbbbpsXUYK6yipYWZUkSZLUiGFVa8abb9ZNAQYYOBB6987fG1YlSZIklTCsqvOlVFdZLYqoq64aViVJkiSVMKyq882ZA4sWNaysgmFVkiRJUrMMq+p8pSsBFxUXWTKsSpIkSSphWFXnK+6xWn8aMMDQodCtGwwatObHJEmSJKmqrVfpAWgdMHVqPpaG1dNPhxEj3LpGkiRJUiNWVtW5amrgpptgr73qVv8t6t0bDjigMuOSJEmSVNWsrKpzXXstzJgBt99e6ZFIkiRJ6kKsrKrzLFkC3/8+fOYzcPDBlR6NJEmSpC7EsKrO85e/wMKF8PWvV3okkiRJkroYw6o6z7hxEAGf+ESlRyJJkiSpizGsqvOMGwe77AL9+lV6JJIkSZK6GMOqOseKFfDMM672K0mSJKldDKvqHC+/nN9X3X//So9EkiRJUhdUNWE1IraKiFsiYmZELI2I6RFxbUT0L7Of4yLi0YiYHxG1ETE5Ii6JiJ5NXHtZRKRWvt4ouefgVq6/anV/F2uFcePy0cqqJEmSpHaoin1WI2II8AywKXAfMAXYG/gmcGRE7J9SmtuGfr4LXAwsAu4G5gIHAGOAURFxeEqppt4tj7fQ3THAHsCDzbQ/0cz941ob5zph3DjYckvYeutKj0SSJElSF1QVYRW4gRxUz0kpXVc8GRHXAOcBVwBntNRBROwOXATMB/ZMKU0rnA9gLHA2cAFwWfGelNLjNBE4I6I78JXCxxubeeTjKaXLmmnT00/nqmpEpUciSZIkqQuq+DTgiNgOGAVMB64vab4UWAx8ISJ6t9LVcUAANxeDKkBKKQEXAgk4sxBEW3M0sBXwXEppYlt+DtXz9tswY4ZTgCVJkiS1W8XDKnBo4fhwSmll/YaU0kLgaWBDYN9W+tmscJxW2lDoZw65ertrG8b0tcKxuaoqwPYRcXZEXBgRX46IoW3od91QfF/VxZUkSZIktVM1hNUdC8fXmmmfWjju0Eo/cwrHbUsbIqIPsEnh404tdRIRWwJHAQuAO1q49J+B68hTlH8GvBYRd5W7INRaadw46NMHdm3L3wtIkiRJUmPVEFb7Fo4Lmmkvnu/XSj8PFI5fjYjBJW3fI08RBmgtTH4V6A78MqW0pIn22cBocoW2DzCIHG5fAE4A7o+Iavi9Vs7TT8N++8F61fJKtCRJkqSupiukiWLITC1dlFJ6JiJ+CnwdmBgRdwPzgP2BvYBXgJ2BFc0+KIfMLxc+NjkFOKX0SqGvokXAQxHxDPBi4XnHkFc1buoZX6MwzXjrtXGl3AUL4KWX4IQTKj0SSZIkSV1YNVQAi5XTvs20b1xyXbNSSmeQV/GdBJxEXkH4Q+AI4KXCZbNa6OIoYGvasbBSSukD4NeFjyNbuO7GlNKIlNKIQYMGlfOIruHVVyEl+PjHKz0SSZIkSV1YNVRWXy0cm3sntbhwUXPvtDaQUroFuKX0fETcXPj2+RZuLy6s9NO2PKsJswvH1lYuXnu9/no+DnW9KUmSJEntVw2V1ccKx1Gl73oWFkbaH6gBnmvvAyJiFLAN8ERK6d1mrtkC+BS5gntnOx9VXLG40YrE64ypU/PeqtttV+mRSJIkSerCKh5WU0pvAA8Dg4FvlDSPIVcpb08pLS6ejIidIqLRqr4RsXET54aQ3z9dQV4YqTlfIS+s9ItmFlYq9rd/UwsoRcSpwOfJ047bG3a7vtdfh49+FHr2rPRIJEmSJHVh1TANGOAs4BlgbEQcBkwG9gEOIU//vajk+smFY5Sc/1lEbANMAN4HticvdtQD+GpKqcnqbCF8fqXwsaW9VQF+BXQrLKj0DtCTvIDT3sBy4Osppemt9LH2ev112H77So9CkiRJUhdXFWE1pfRGRIwALgeOBI4G/g6MBcaklOa1sasHyO+dnkTeVmYWcDfwH60smHQEeZrwcymll1q4DuDHwCfJ05M3IQfmd4GfA9emlP7WxrGunaZOdSVgSZIkSautKsIqQEppBvClNl5bWlEtnr8NuK0dz36QxlXa5q79AfCDcp+xTnj/fZg718WVJEmSJK22ir+zqrVIcSVgpwFLkiRJWk2GVXUcw6okSZKkDmJYVccphtUhQyo7DkmSJEldnmFVHefVV2GrraBXr0qPRJIkSVIXZ1hVx/nrX2G33So9CkmSJElrAcOqOsaiRTBlCuy5Z6VHIkmSJGktYFhVx3jxRUjJsCpJkiSpQxhW1TH++td8NKxKkiRJ6gCGVXWMCRNgs81giy0qPRJJkiRJawHDqjrGhAlWVSVJkiR1GMOqVt/ixTB5smFVkiRJUocxrGr1/elPsHIlfOITnfqYpUvhyiuhpqZTHyNJkiSpChhWtfpuvx0GDYJDD+3Uxzz8MFx0ETz5ZKc+RpIkSVIVMKxq9bz/Ptx/P5xyCvTo0amPmjw5Hxct6tTHSJIkSaoChlWtnv/5H/jwQ/jCFzr9UZMm5aNhVZIkSVr7GVa1en73Oxg6FPbYo9MfVaysLl7c6Y+SJEmSVGGGVa2eSZPyKsARnfqYlAyrkiRJ0rrEsKr2W7IEpk+HYcM6/VHvvgsLF+bvDauSJEnS2s+wqvZ79dVc8lwDYbVYVQXfWZUkSZLWBYZVtV8xQX7sY2vsUT16WFmVJEmS1gXrVXoA6sImT4bu3fMCSx1k8WJYbz3YYIPGj+rfH/r2NaxKkiRJ64I2V1YjYvfOHIi6oEmTYMgQWH/9Duvy8MPh/PObftSwYdC7t2FVkiRJWheUMw14QkT8OSK+HBEbdtqI1HVMntzh76u++SY8+2zTj/rYx2CjjQyrkiRJ0rqgnLD6B2AP4CZgZkRcFxG7ds6wVPWWLYOpUzv8fdXFi2HKFFi5su7cnDkwe3ZdZdUFliRJkqS1X5vDakrp08Bg4LvAB8A3gBcj4umI+JeI6Nk5Q1RVmjYNli8vu7L6y1/mfLt8eeO2lHJYXbIEZsyoO19cXKn+NOB//AM22wwee2w1fgZJkiRJVaus1YBTSu+mlC4jh9ZjgQeBvYFbgXcj4kcR0fn7mKjy3n03H7feuqzb/ud/cvicNq1x29KldRXV+lvV1F90uBhWp06F996Diy/OIVeSJEnS2qVdW9eklFamlO6vV229HPgQOAd4OSIej4gTO26Yqjpz5+bjwIFtvmXlSnjqqfz9pEmN2+u/i1q/ffJk2HBD+OhH68LqvHm57Zln4Iknyhy7JEmSpKrXEVvX7AwMBwYCAcwBDgQOjIgXgRNSStM74DmqJu0Iq5Mmwfvv5+8nT4ZNN4Urr4R7783b1dQPq/Urq5MmwU47QbdueYGlRYvq+unVC37wAzj44IbPuuceuP9+uOWW8n+0rurWW/Pv00pz19GnD/zud/kvYrR2O//8vPXWJZc0PH/llQ3/nNp/f7jtNrjppvxnW/fuMHYsHHHEmh1vfXfemWex1F9LQKoGffrk/9ZvtVWlRyKps7QrrEbEpsCXgdPJlVWAPwE3AL8DtgG+DXy9cO7o1R2oqsycOflYRlh98sl87NUrh9E334Tf/z5P591yy4YLJ5VOAz7ooPx9sbJazMpHHAETJjR+1gMP5PD2X/+V/2O2tqupgdGjoV8/2GuvSo9GbZFSnhZ/1VVw/fWVHo0600svwTXX5L+UO+20urcn/v53uPzy/IrDxz6WP99+O5x8Mvzbv8GgQbBwIVxwAYwaBRFrfuzLlsF3vpND8377rfnnS81JKf9Fyg9+ANddV+nRSOosZYXViDiMHECPBXoA7wPXAj9OKb1e79I3gbMiYgPgpA4aq6rJ3Lk5BZaxx+pTT+VQOmxYDqALF+bzCxbk88XK6pZb5mpqccGlGTPq1nHq3RtWrMgBt3t3GDwY/vjHxs8qZukpU9aN8HbzzTBrVg4/I0dWejRqq1694Gc/y1WrzTev9GjUWb7//fxn19Kl8J//Wfd/rH/4wxwG/+d/8pbVNTX5z7TPfS7/2Xf//fDaazng/v738OlPr/mx/+pX8NZb+S8AP/WpNf98qSU9e+b//l18MXzkI5UejaTO0OawGhFTge3IU33Hkyumv00p1bZw21Sg92qNUNVpzhzYZJM2X55SrqwedFC+7ac/hQ8/zG3z5+djMayOGAH33ZcDaXFV4PphFfL5fv1yYXfx4txX/dw8e3Y+Tp7cdFi97DI48EA47DD47nfhL39p849SlZ59Nv88BtWuZfToPAPgqKOcCry2SgkefDBPA543L0/vnT49t/3pT3DKKTmoQv7Li/PPz5XUQw/NlcwRI/KfV2edlf/cXNOefx522w2Odn6UqtDo0fDzn+dZVv4ZKrXuhBPyX4B2JeVUVrcEfg7ckFJqYuJlk34FPFvuoNQFzJ1b1hTgadNg5swcplKqC6qQK6tQF1aPPjqH1dtug7ffhh49YN99c9tGG+XjjBkwYAD0758/v/9+w79VLVZW608nLho3DsaMgaFD4de/zu+QDRmS3yfrqoYMydNJ1bVsvz38+7/nCtrMmZUejTrLyJE5hNbU5Nkexf+td9+98TusZ56ZF467+OL8uUePPIX4iisq88/I1lvnynAlpiBLrRk6NP+78sAD/hkqtUVxVmNXUk5Y3SKlNL+czlNKM4AZrV6orqfMsFpcBfjAA+uqnkWlYfWAA/L7WVdfnf+lOu20uimS9Surm22WAyvkikX9sFq/slrqiivyu2NTp8Jxx8HGG8P48blSK61pl12Wv7RuGDeu5fY+ffKic/Udd1z+ktTYmDH5S9Laqc1b15QbVLUWmjIlp8UpU8qeBvzkkznbDhuWFxKBuqm9pdOAe/eGiy7Kj1i2LE+JKyqG1XffbVxZnTw5T7dbtqyuz/pb4Nx8M3zzm/DQQ/k/bMOGwTvvwNlnG1QlSZKkatPmsBoRZ0TEGxGxRTPtWxbav9Jxw1NVefllWLIkv8TUjsrqgQfm7WcGDcpbzZx1Vm4rVlaLqwH37p2nzR1/fA6Sxfe5im2QF1kaMKBhZfXKK+HUUxvuqvPGG3lRk+efh9NPhx//OPd39tl5atsOO8C557b/VyJJkiSpc7Q5rAKnAH9PKTX5VkBK6V3gHeDU9gwkIraKiFsiYmZELI2I6RFxbUT0L7Of4yLi0YiYHxG1ETE5Ii6JiJ7NXJ9a+Hquhed8OiIej4gFEbEoIv4cEV8s9+fuUoovgr76ak6YbayszpwJr79et/hPBDz2GHzjG3k6buk04GIgvfvuvPVMfb3rLdfVv3/DyurMmTm0TpuWzx14YN4XcOrUHGT79cs/wuuv56m/xx6bf5RBg8r8PUiSJEnqdOW8s7ojcFcr10wETix3EBExBHgG2BS4D5gC7A18EzgyIvZPKc1tQz/fBS4GFgF3A3OBA4AxwKiIODylVNPErW+RF48q9U4zzzkbuK7Q/y+BD8k/988jYteU0rdaG2uXVHwRdPz4fGxjZbX++6r1ReQAWX8acEReir45xQWWoHFl9R//yN//9a91z7v3Xrj22ny85JIcUiVJkiRVv3LCal+gtfdWPwDKqoQW3EAOqueklFZt7RwR1wDnAVcAZ7TUQUTsDlxUGOOeKaVphfMBjAXOBi4ALmvi9ukppabON/WcwcDVwDxgREppeuH85cDzwPkRcXdKae1bBblYWS3u89LGyuqf/wwbbpi3PyjVt2/Dymrv3i2vOllaWS2+azpvHvz97/n7CYW1qg84IC9W8rOf5eecc06bhitJkiSpCpQzDfjvwPBWrhkOzG7lmgYiYjtgFDAduL6k+VJgMfCFiGhtv9bjyHvA3lwMqgAppQRcCCTgzIjoXs74mvBlYAPgv4tBtfCc94ErCx9bDNZdVjGsvv9+PraxsjppEuy0U57yW6qpsNqS+u0DBkD37rmPf/yjbljFsLr11nk/w9dey1ODy3jFVpIkSVKFlRNWHyNPyT2gqcaIOBA4CvhTmWM4tHB8OKW0sn5DSmkh8DSwIbBvK/1sVjhOK20o9DOHXL3dtYl7+0XElyPiwoj4RkS09KzieB9qou3BkmvWLrNnM5XtmciuLGSjNqe/yZPrVv4t1bdvw2nA9af5NqW0sgo5tNbfoqa4AvDAgblt6NC66cKSJEmSuoZywuoPyO9mPhIR10TEqIjYuXD8EfBHYGnhunLsWDi+1kz71MJxh1b6KZT92La0ISL6AMU5qzs1ce/HgZ+Rpxv/N/BsRLwYEU0F22bHm1L6O7kSvFVEbNjKeLuc37+xEzswlY8zkWO5r03TgBctgrffbj6s9uvXcDXg1iqrvXrVTRMuBtD+/RtuUbNiRe63R49WhydJkiSpSpWzz+qrwEnkQHouuYo4sXD8JlALfC6lNLnZTprWt3Bc0Ex78XxrO2E+UDh+tfBeaX3fI08Rhsbv1F4D7A8MAvoAe5EXkvo48GhEbNnO8fZtpr1LSgkuf+dLDO7xDp/nt4zjAJb0ar2y+uqr+dhSZbWcacARddcUw+qAAXXb1RTfYS1jC1hJkiRJVaicyioppd8D2wHfJq+2+6fC8VvAkJTSHzp8hHUhM7UytmeAn5LD6MSIuDUifljYfuZs4JXCpStK7js/pfRMSmlOSmlRSml8Sulz5J9rE/LP1mHjjYivRcT4iBg/e3ZZr/dW1KN/Svzlw90ZPeJPfIFfsIz1+fPEXq3eV5ye29ZpwK2FVai7pjgNuH+9v37Ye+98dDsaSZIkqWsrK6wCpJTmppR+mFI6KaU0qnC8pi1byzSjtUrkxiXXtTS2M4CvAJPIVeAzyFOXjwBeKlw2q43j+knhOLKd4/2gmTHemFIakVIaMagLJaof/XAFmzOTLx41i/37vESwctWWNPPmwXbbwfPPwwcfwJAh8Lvf5bbJk/PCSttv33S//frBwoV56m57w2qxwhoBI0bk762sSpIkSV1b2WG1ExQmijb7TurQwrG5d1obSCndklLaN6XUu/A1MqX0CLBf4ZLn2ziuYtmzND41O96I2Lxw/TsppSVtfE6X8PzzwVE8SM8tBtBv+00Y3nPqqrD65pv565FH4G9/yyvvXnQRrFyZw+qQIc2/P9q3EPkXLiwvrPbqVbcfazG0brppDs1gZVWSJEnq6srZZ3WViNgK2JK8hUsjKaUny+juscJxVER0q78icGFhpP2BGuC59oy10M8oYBvgiZTSu228rbgicOnqwo8WxnQkULqX6lH1rllrzJsHs+Z2ZxiTYdBIOPdcDvz5cm59FpYvz9VUgClT6hYIfvlluP/+llcChrqwOn9+XmCptdWAIV9Tf3Xf4vebbQbbbJO/t7IqSZIkdW1lVVYLK/++ArwFPEMOmk19tVlK6Q3gYWAw8I2S5jHkSuXtKaXF9caxU0Q0WtU3IjZu4twQ4Ebyu6qjS9r2aGr/1ogYTl4ZGOCXJc23kheZOrv+Qk4R0Z+8nyvUTSFeK0yZko/DmJxT4L/8CweesTOLF8MLL+SqKORgOnlyrnputx185St5j9OWwmpxQaQFC8qrrNZ/T7X4ff2wamVVkiRJ6traXFmNiH3IK+7OJm/v8q/AE+RpsQcCw4DfAS+0YxxnkcPv2Ig4DJgM7AMcQp7+e1HJ9cUVh6Pk/M8iYhtgAvA+sD1wDNAD+GpKqbQ6ew5wfEQ8Cswgh9CdyFXT7sBNwG/q35BSejMivg2MBcZHxB3k92JPBLYCfphSKq24dmnFRZJ2YsqqFFgMoG+9BbW1+fspU3KVc8cd4aqr4IYboHt3+Kd/ar7v+pXVtobVs8+uC8hQV1ndfPM85fg734HjjivjB5QkSZJUdcqZBnwheXuavVJKMyPiX4HHUkqXR0QAlwHn0zhYtiql9EZEjAAuJwfFo4G/kwPhmJTSvDZ29QDwNfLiSn3IiyndDfxHSmliE9ffS14QaThwKNATmEvejuemlNLvmhnvdRExnbxS8L+QK9zw4LwAACAASURBVNSTgItTSre1caxdxuTJsMF6yxm8fPqq+bXFkLlgAXz4Yf5+4UJ4+mk45hg44oj81ZpiP++9l7fHaUtYPfbYhp/rTwPu1g1+UO5Ov5IkSZKqTjlhdT/gdymlmfXOdQNIKSXg0og4mjx198RyB5JSmgF8qY3XllZUi+dvA9ocFlNK95IDa9lSSvcD97fn3q5m8mTYccBsus+NVemyflhdtqzu2kWLWp72W6o4DXhm4Z+qtoTVUsVpwJtvXv69kiRJkqpTOWG1L/B2vc8f0nil3KeBU1Z3UKouU6bAXhu9A7FJLl0CffrkrWLmz8+r/ta3U6O3iZtXDL3vFpa9ak9Y3X57OOggOPjg8u+VJEmSVJ3KCauzgP4ln4eUXNMD6LW6g1L1qKnJ29J8Ycdp0Ktuid1u3WDjjXNlNaWGldZyKqsdEVZ794bHHy//PkmSJEnVq5zVgF+jYTh9Djg8InYAiIjNgBOAqR03PFXaa6/lMDps5SuN9oPp2zeH04ULc3AdNiyH2KFDm+msCeuvn1cPLk4DbsvWNZIkSZLWfuWE1YeAgyKiuMPlf5GrqC9ExPPAFGAQcG3HDlGV9OCD+bj72/fBrrs2aCsNqyNHwr77wgZN7r7bvK22ylvgQPsqq5IkSZLWPuWE1Z8CI4FlACmlp4HPAW8Cu5BX7z0zpXR7Rw9SlVFTAz/6EYza+312qJ0IhxzSoL1v3/zO6gcf5HdYr7oKxo0r/zlnnZX7AMOqJEmSpKzNYTWl9EFK6c8ppYX1zt2TUtolpdQrpTQspXRj5wxTlXDrrTBrFly46wP5xMiRDdpLK6sR+atcp58OAwfm7w2rkiRJkqCMsBoRt0TEeZ05GFWX66/P03pHvnkbDB/e7Durxcpqe/XuDeedl4NuMbRKkiRJWreVMw34FGDTzhqIqsusWTBpEnz208uJZ59pcl+Yfv0aVlZXx+jR8Le/wUc+snr9SJIkSVo7lLN1zXQMq+uMp5/OxwMHvJJfXi15XxXqKqvLl69eZRWge/dG6zdJkiRJWoeVU1n9NXBURPRv9Up1eU89BT17wohFj+cT++3X6Jq+fXNQXbBg9SurkiRJklRfOWH1+8B44LGI+HREOGFzLfbUU7DPPrD+xPGwxRZNzs/t27fu+9WtrEqSJElSfeVMA64tHAO4DyCaXvo1pZTK6VdVZtGivO/p6NHAvS/AHns0eV39sGplVZIkSVJHKidUPgWkzhqIqsdzz8GKFXDgXrXw/clw/PFNXmdlVZIkSVJnaXNYTSkd3InjUBWZMSMfd1g5BVaubLay2q9f3fdWViVJkiR1pHLeWdU6orYw4bvXqy/mb3bfvcnrrKxKkiRJ6iyGVTVSU5OPvaa8AAMGwNZbN3md76xKkiRJ6ixtngYcEZe08dKUUvpuO8ejKrCqsvry87mq2vRCWoZVSZIkSZ2mnAWWLmuhrbjwUhS+N6x2YTU1OZ/2eO8d2PWwZq/baCPo1i2/1uo0YEmSJEkdqZywekgz5/sBewHnAL8HfrK6g1Jl1dZCr14QC+Y3XEWpRESuqM6fb2VVkiRJUscqZzXgJ1povi8i7gD+Avx2tUeliqqpgZ49E8xbCP37t3htv36wcCH07LmGBidJkiRpndBhCyyllF4C7gMu7Kg+VRm1tdBrg5X5QythtW/fXFVt5rVWSZIkSWqXjl4N+G1glw7uU2tYTQ307LEif2hhGjDksOr7qpIkSZI6WjnvrLbFPkBNB/epNay2Fnr1WJ4/tFJZ3XRTWLRoDQxKkiRJ0jqlnK1rmt5sM/fxUeB04ADgzg4YlyqopgZ6dl+WP7RSWf3P/4QlS9bAoCRJkiStU8qprE6nbouapgQwFfjW6gxIlVdbC726fZg/tFJZHTy488cjSZIkad1TTli9nabD6krgffJKwPellJZ2xMBUOTU1sHG32vyhlbAqSZIkSZ2hnK1rTuvEcaiK1NTApqkQVluZBixJkiRJnaGjVwPWWqC2FnqlJbD++tCrV6WHI0mSJGkd1OawGhFDIuJfImJgM+2bFNq367jhqRJqaqDnysV5CrAbqEqSJEmqgHIqq6OBHwIfNNO+ALga+PbqDkqVVVsLvVYscgqwJEmSpIopJ6weDDySUlrWVGPh/B+BQztgXKqgmhrouWyRiytJkiRJqphywuqW5O1rWvI2sEW7R6OqUFsLvT5cYGVVkiRJUsWUE1Y/BDZu5Zo+tLwXq6rcihWwbBn0/PADK6uSJEmSKqacsPoy8KmI6NFUY0SsD3wamNQRA1Nl1BZ2rOlV+75hVZIkSVLFlBNWfwlsDdwZEZvVbyh8vhP4KHB7xw1Pa1pNTT72qpnnNGBJkiRJFbNeGdfeCJwAHAscHhETgXfJ77IOBzYEHgF+0tGD1JpTrKz2TEug/9aVHYwkSZKkdVabK6sppZXA0cBVwDJgX3J43Zf8PuuVwKcK15UtIraKiFsiYmZELI2I6RFxbUSUNRc1Io6LiEcjYn5E1EbE5Ii4JCJ6NnHtlhHxrxHxYOF5SyNibkT8MSKOb6b/gyMitfB1VXt+/mqxqrJKjZVVSZIkSRVTTmW1uD3NhRFxMbAT0A+YD0xpb0gFiIghwDPApsB9wBRgb+CbwJERsX9KaW4b+vkucDGwCLgbmAscAIwBRkXE4Smlmnq3/CtwAfAm8BjwD2Ab4HjgkxHxo5TS/2vmcU8Ajzdxflxr46xmqyqr1PrOqiRJkqSKKSusFhWCaUcupHQDOaiek1K6rngyIq4BzgOuAM5oqYOI2B24iBye90wpTSucD2AscDY5mF5W77a/AAenlJ4o6WsY8BxwXkT8KqU0oYlHPp5SuqyJ811ag8qqYVWSJElShbR5GnBEDImIf4mIgc20b1Jo366cARSuH0Xew/X6kuZLgcXAFyKidytdHQcEcHMxqAKklBJwIXlLnTMjonu9tv8tDaqF85OBOwofDy7n5+nqimG1J7VOA5YkSZJUMeWsBjwa+CHwQTPtC4CrgW+XOYZDC8eHS6cSp5QWAk+TF2/at5V+iisUTyttKPQzh1y93bWN41pWOC5vpn37iDg7Ii6MiC9HxNA29lvVVm1dQw306VPZwUiSJElaZ5UTVg8GHim8t9pI4fwfqQufbbVj4fhaM+1TC8cdWulnTuG4bWlDRPQBNil83Km1AUXExuTFoxLwcDOX/TNwHXmK8s+A1yLirnIXhKo2DSqrPZrcUleSJEmSOl05YXVL8lTdlrwNbFHmGPoWjguaaS+eb21O6gOF41cjYnBJ2/fIU4QBWgyThXdcbwY+Avy4MCW4vtnkKvOuQB9gEHAU8AI54N4fEc3+XiPiaxExPiLGz549u5Ufac1rUFldr12vNEuSJEnSaisnjXwIbNzKNX3I1ciOVAyZLfabUnomIn4KfB2YGBF3A/OA/YG9gFeAnYEVrTzvh8DngKeARisBp5ReKfRVtAh4KCKeAV4sPO8Y8qrGTY3zRvKetYwYMaKjf1errcECS4ZVSZIkSRVSTmX1ZeBTEdHk3NCIWB/4NOWvElysnPZtpn3jkuualVI6A/hKYQwnkVcQ/hA4AnipcNms5u6PiP8krz78JHB0Smlpa8+s9+wPgF8XPo5s633VpsHWNYZVSZIkSRVSTlj9JbA1cGdEbFa/ofD5TuCjwO1ljuHVwrG5d1KLCxc1905rAymlW1JK+6aUehe+RqaUHgH2K1zyfFP3RcSPgG+R91s9KqW0qG3Db6A4r7e1lYurlpVVSZIkSdWgnDRyI/mdzGOBwyNiIvAu+V3W4eQVex8BflLmGB4rHEdFRLf6KwIXFkbaH6gh73vaLhExCtgGeCKl9G5JWwD/DZxFXiDq2JRSTTsfVVyxuNGKxF2FlVVJkiRJ1aDNldVCiDwauIq8rcu+5PC6L3mq7ZXAp0q3n2lDv2+QV9wdDHyjpHkMuUp5e0ppcfFkROwUEY1W9S2s4lt6bgg5aK8gL4xUvy0KbWcBDwKfaS2oRsT+TS2gFBGnAp8n/y7ubKmPalZTA91iJT1YZliVJEmSVDFlpZHC9jQXRsTF5C1g+gHzgSkppZUR0S0ijk0pNbm4UAvOAp4BxkbEYcBkYB/gEPL034tKri+u0Bsl538WEdsAE4D3ge3Jix31AL6aUiqtzl4CfJVcuX0RGJ3zawMvppTurff5V0C3woJK7wA9yQs47U3ek/XrKaXpbfuxq09tLfRcbzmxDMOqJEmSpIppVxopVE9XLaQUEdtExFeBLwGbA93L7O+NiBgBXA4cSa7g/h0YC4xJKc1rY1cPAF8jL67Uh7yY0t3Af6SUJjZxfXFP1l7AvzXT521A/bD6Y+CT5OnJm5AD87vAz4FrU0p/a+NYq1JNDfRab3munXcv639GSZIkSeow7S6dRUR38vurXyOHt27k7WUeaU9/KaUZ5LDblmsblT8L528jh8u2PvM04LS2Xl+45wfAD8q5pyupqYGe6y3LQbVxlVmSJEmS1oiyw2pEbEeeOnsa8JHC6TnAT4GfpZTe6rDRaY2rrYVe6/m+qiRJkqTKalMiiYj1gOPIVdRDyFXUD4H/JS+ydF9K6ZLOGqTWnJoa6NX9Q8OqJEmSpIpqMZFExFDgdOCL1L2f+Vfy+5m/TinNi4iyVv9VdauthZ7draxKkiRJqqzWEsmr5PdQZwE/Am5NKb3S6aNSxVhZlSRJklQN2rLPagL+ANxlUF371dZCz26GVUmSJEmV1VpY/XfgLfIqvU9HxKSI+E5EbN75Q1Ml1NRAL8OqJEmSpAprMaymlK5IKQ0BjgLuAYYAVwFvR8TvI+KkNTBGrUFWViVJkiRVg7ZMAyal9H8ppROBjwIXkqutRwG/IU8T3i0i9uy0UWqNyZXVpYZVSZIkSRXVprBalFKalVK6KqW0PXA4cBewDBgB/CUiXoiIb3TCOLWGXH89nLnd/xlWJUmSJFVUWWG1vpTSn1JKnwe2Ar4DvAZ8HBjbQWNTBXz607B331cNq5IkSZIqqt1htSilNCeldHVKaRhwKHlqsLqy5csNq5IkSZIqqkMTSUrpceDxjuxTFWBYlSRJklRhq11Z1VrIsCpJkiSpwgyrasywKkmSJKnCDKtqzLAqSZIkqcIMq2rMsCpJkiSpwgyrasywKkmSJKnCDKtqzLAqSZIkqcIMq2rMsCpJkiSpwgyrasywKkmSJKnCDKtqzLAqSZIkqcIMq2ps+XLo3r3So5AkSZK0DjOsqjErq5IkSZIqzLCqxgyrkiRJkirMsKrGDKuSJEmSKsywqsYMq5IkSZIqzLCqxgyrkiRJkirMsKrGDKuSJEmSKsywqsYMq5IkSZIqzLCqxlasMKxKkiRJqijDqhpKycqqJEmSpIozrKqhlSvz0bAqSZIkqYIMq2po+fJ8NKxKkiRJqiDDqhoyrEqSJEmqAoZVNWRYlSRJklQFqiasRsRWEXFLRMyMiKURMT0iro2I/mX2c1xEPBoR8yOiNiImR8QlEdGzhXs+FhF3RsSswj2vRsSYiOjVwj2fiIg/RMS8iFgSERMj4tyI6F7OeKuOYVWSJElSFaiKsBoRQ4AJwJeAvwA/AqYB3wSejYiBbeznu8D/AnsB9wLXAx8AY4BHmgqfEbEP8DzwWeAR4L8K91wC/DEiNmjinmOBJ4GRwD2F56xfGPdv2/pzVyXDqiRJkqQqUC2J5AZgU+CclNJ1xZMRcQ1wHnAFcEZLHUTE7sBFwHxgz5TStML5AMYCZwMXAJfVu6c7cCuwIXBsSul3hfPdgDuBEwrPv6rePRsDNwErgINTSuML5/8deBQ4MSJOTil1zdBqWJUkSZJUBSpeWY2I7YBRwHRyhbK+S4HFwBcioncrXR0HBHBzMagCpJQScCGQgDNLpukeBAwDniwG1cI9K4HvFD6eUQi8RScCg4DfFoNq4Z5a4OLCxzNbGWv1MqxKkiRJqgIVD6vAoYXjw4WQuEpKaSHwNLnyuW8r/WxWOE4rbSj0M4dcvd21iWc/1MQ904DXgG2A7dpyD3lq8BLgE01NH+4SDKuSJEmSqkA1hNUdC8fXmmmfWjju0Eo/cwrHbUsbIqIPsEnh406r+exm70kpLQfeJE+v3q60vUswrEqSJEmqAtUQVvsWjguaaS+e79dKPw8Ujl+NiMElbd8jTxEGqL+6cHuevVrjjYivRcT4iBg/e/bsZrqoIMOqJEmSpCpQDWG1NcWQmVq6KKX0DPBTchidGBG3RsQPI+I58uJKrxQuXdHRzy7nnpTSjSmlESmlEYMGDSqj2zXEsCpJkiSpClRDWC1WIvs2075xyXXNSimdAXwFmAScRF5B+EPgCOClwmWzVvPZHTbeqmRYlSRJklQFqiGsvlo4NvdO6tDCsbn3ShtIKd2SUto3pdS78DUypfQIsF/hkudX89nN3hMR65HfmV1OEws9dQmGVUmSJElVoBrC6mOF46jC/qarFBZG2h+oAZ5r7wMiYhR5Vd8nUkrv1mt6tHA8sol7tiMH0rdoGDybvQcYSV65+JmU0tL2jreiDKuSJEmSqkDFw2pK6Q3gYWAw8I2S5jFAb+D2lNLi4smI2Ckidiq5lojYuIlzQ4Abye+qji5pfgKYDIyMiM/Uu6cb8IPCx58U9motuou88vDJETGi3j09yQs5Afy4uZ+36hlWJUmSJFWBakkkZwHPAGMj4jBygNwHOIQ8BfeikusnF45Rcv5nEbENMAF4H9geOAboAXw1pdSgOptSWhERXyJXS++KiLuAt4HDgBHkPV5/VHLPBxFxOjm0Ph4RvwXmAZ8hb2tzF3BHe34JVcGwKkmSJKkKVLyyCquqqyOAn5ND6vnAEGAssF9KaW4bu3oAWEZeXOlbwCeAu4E9Uko/b+bZfwb2Au4DRgHnkRdPuhw4vKnpvCmle4GDgCeBE4B/LTz3/wEnl1RiuxbDqiRJkqQqUDWJJKU0A/hSG68tragWz98G3NaOZ08CPlfmPU8DR5f7rKpnWJUkSZJUBaqisqoqYliVJEmSVAUMq2rIsCpJkiSpChhW1ZBhVZIkSVIVMKyqIcOqJEmSpCpgWFVDhlVJkiRJVcCwqoYMq5IkSZKqgGFVDRlWJUmSJFUBw6oaMqxKkiRJqgKGVTVUDKvdu1d2HJIkSZLWaYZVNWRlVZIkSVIVMKyqIcOqJEmSpCpgWFVDhlVJkiRJVcBEooYMq5IkSVrHLVu2jHfeeYfa2tpKD2Wt0bNnT7baait69OjR5ntMJGpoxQqIgG4W3SVJkrRueuedd+jTpw+DBw8mIio9nC4vpcTcuXN555132Hbbbdt8n4lEDS1fblVVkiRJ67Ta2loGDhxoUO0gEcHAgQPLrlQbVtWQYVWSJEkyqHaw9vw+DatqyLAqSZIkVdz8+fO54YYbyr7v6KOPZv78+S1ec8kll/DII4+0d2hrjGFVDRlWJUmSpIprLqyuWLGixfv+8Ic/0K9fvxavufzyy/nkJz+5WuNbEwyrasiwKkmSJFXc6NGjeeONN9htt93Ya6+9OOSQQzjllFPYddddAfjsZz/Lnnvuyc4778yNN9646r7BgwczZ84cpk+fzrBhwzj99NPZeeedGTVqFDU1NQCcdtpp3HXXXauuv/TSS9ljjz3YddddmTJlCgCzZ8/m8MMPZ4899uDrX/8622yzDXPmzFmjvwNTiRoyrEqSJEl1zj0XXnyxY/vcbTe49toWL7nqqqt4+eWXefHFF3n88cf51Kc+xcsvv7xqNd1bbrmFAQMGUFNTw1577cUJJ5zAwIEDG/QxdepUfvOb33DTTTdx0kkncffdd3Pqqac2etYmm2zCX//6V2644Qauvvpqbr75ZsaMGcOhhx7Kv/3bv/HQQw81CMRripVVNWRYlSRJkqrO3nvv3WDbl7Fjx/Lxj3+cfffdlxkzZjB16tRG92y77bbstttuAOy5555Mnz69yb6PP/74RteMGzeOk08+GYAjjzyS/v37d+BP0zamEjVkWJUkSZLqtFIBXVN69+696vvHH3+cRx55hGeffZYNN9yQgw8+uMltYTbYYINV33fv3n3VNODmruvevTvLly8H8t6olWZlVQ0ZViVJkqSK69OnDwsXLmyybcGCBfTv358NN9yQKVOm8Nxzz3X48w844ADuvPNOAB5++GHef//9Dn9Ga0wlasiwKkmSJFXcwIED2X///dlll13o1asXH/nIR1a1HXnkkfzkJz9h+PDh7Ljjjuy7774d/vxLL72Uf/qnf+KOO+7goIMOYvPNN6dPnz4d/pyWRDWUd9dVI0aMSOPHj6/0MBo6/nh4/XWYOLHSI5EkSZIqYvLkyQwbNqzSw6iopUuX0r17d9Zbbz2effZZzjzzTF5czYWmmvq9RsSElNKIpq63hKaGrKxKkiRJ67y3336bk046iZUrV7L++utz0003rfExmErUkGFVkiRJWucNHTqUF154oaJjcIElNWRYlSRJklQFDKtqyLAqSZIkqQoYVtWQYVWSJElSFTCsqiHDqiRJkqQqYFhVQ4ZVSZIkqcvZaKONAJg5cyYnnnhik9ccfPDBtLZ15rXXXsuSJUtWfT766KOZP39+xw20DIZVNWRYlSRJkrqsLbbYgrvuuqvd95eG1T/84Q/069evI4ZWNsOqGjKsSpIkSRV3wQUXcMMNN6z6fNlllzFmzBgOO+ww9thjD3bddVfuu+++RvdNnz6dXXbZBYCamhpOPvlkhg8fzuc//3lqampWXXfmmWcyYsQIdt55Zy699FIAxo4dy8yZMznkkEM45JBDABg8eDBz5swB4JprrmGXXXZhl1124dprr131vGHDhnH66aez8847M2rUqAbPWR2mEjVkWJUkSZJWOfdcePHFju1zt92gkPWadfLJJ3Puuedy1llnAXDnnXfy0EMPcd5557HxxhszZ84c9t13Xz7zmc8QEU328eMf/5gNN9yQiRMnMnHiRPbYY49VbVdccQUDBgxgxYoVHHbYYUycOJFzzjmHa665hscee4xNNtmkQV8TJkzg1ltv5c9//jMpJfbZZx8OOugg+vfvz9SpU/nNb37DTTfdxEknncTdd9/Nqaeeunq/JKqoshoRW0XELRExMyKWRsT0iLg2IvqX2c8BEXFf4f7aiHg7Iv4QEUc2ce1lEZFa+Xqj5J6DW7n+qtX9XVSUYVWSJEmquN13351Zs2Yxc+ZM/va3v9G/f38233xzLrzwQoYPH84nP/lJ3n33Xd57771m+3jyySdXhcbhw4czfPjwVW133nkne+yxB7vvvjuvvPIKkyZNanE848aN47jjjqN3795stNFGHH/88Tz11FMAbLvttuy2224A7LnnnkyfPn01f/qsKlJJRAwBngE2Be4DpgB7A98EjoyI/VNKc9vQz5nADcBi4B7gHWAr4HjgqIi4OKV0Rb1bHm+hu2OAPYAHm2l/opn7x7U2zqpmWJUkSZJWaa0C2plOPPFE7rrrLv7xj39w8skn86tf/YrZs2czYcIEevToweDBg6mtrW2xj6aqrm+++SZXX301zz//PP379+e0005rtZ+UUrNtG2ywwarvu3fvvtZNA76BHFTPSSldVzwZEdcA5wFXAGe01EFE9AC+D9QCe6aUXq3XdiXwAnBRRFydUloKkFJ6nCYCZ0R0B75S+HhjM498PKV0WRt+tq7FsCpJkiRVhZNPPpnTTz+dOXPm8MQTT3DnnXey6aab0qNHDx577DHeeuutFu8fOXIkv/rVrzjkkEN4+eWXmThxIgAffPABvXv3pm/fvrz33ns8+OCDHHzwwQD06dOHhQsXNpoGPHLkSE477TRGjx5NSol77rmHX/ziF53ycxdVPJVExHbAKGA6cH1J86XA14AvRMT5KaXFLXQ1AOgLTKwfVAFSSpMj4jXg/7d358FylXUax78PYbnKElCQhIR9gGTiQMJc1lCQKAVEiaKGgSmWsAQEEQdnmBqKwSGMhYWlCAIqCgMUgiyDxTCMLAoECCBikJ2ETcIQwhISDHsi8ps/3reZQ9Pn9u2be9On730+VW+91e9y+j33/up0v33Oec/fAGsBy5oM63OkM7L3RsTDvd2XQeGGGyAve21mZmZmZu0zbtw43njjDUaNGsXIkSM56KCDmDp1Kt3d3YwfP54xY8b02P/YY4/l8MMPZ9ttt2X8+PHsuOOOAGy33XZMmDCBcePGscUWWzBx4sQP+hx99NFMmTKFkSNHMmvWrA/Kt99+ew477LAPtjFjxgwmTJjQb5f8NqKeTueuDJJmABcAP4uIrzaov5k0md0zIm7tYTsCXgbWBraNiKcKdVsDDwHzImJCL8Z0PbAvcEREXFxXNwmYBVwO3AusA7wEzC6+Z290d3dHs+ccmZmZmZnZyjV37lzGjh3b7mEMOo3+rpLuj4juRu3bfmYV2CbnT5bUP0WarG4NlE5WIyIkHQdcBtwv6VpgITAK+BLwGHBgs8FIGgVMAZYCV/XQ9KCcin1/CRwVEa81ex8zMzMzMzMrV4XJ6vCcLy2pr5U3fRJtRPynpIXAFcChhaqXgYuBP/ZiPDOAYcBlEfF2g/pFwEnAr0iXLncB3cB3gK8AIyTtHhHvN9q4pKNJlzazySab9GI4ZmZmZmZmQ09lHl3Tg9ryVU2vV5Z0MHALMBsYC3w857cC5wFXNum/CnBEftlwYaWIeCwivhsRj0bEmxHxakTcBEwCngUmklYSbigifhYR3RHRvcEGGzTbJTMzMzMzsyGpCpPV2pnT4SX169S1ayjfl3oR6XLfQyJiXkS8ExHzgEOA+4H98z2nZaYAm9CHhZUi4nXgF/nl7q30NTMzMzOzamn32j6DTV/+nlWYrNZW7t26pH6rnJfd01qzF7AacEf9Jbj59Z355d/2sI2jc/7TJu9VZlHO1+xjfzMzMzMza7Ouri4WL17sCWs/iQgWL15MV1dXS/2qcM9qbT3kvSStUpxoSlqbdFntO6SVDIwOogAADa5JREFUd3tSexJt2bW1tfLljSolbQR8nnQG9+pejLuRnXPem3tjzczMzMysgkaPHs2CBQtYtGhR88bWK11dXYwePbqlPm2frEbEM5J+TTozehxwbqH6NNJZyp8Wn7EqaUzuO6/QdnbOp0n6fvEyXknjgWmk+15vKxnKkaSFlX5esrBSbVsTgd/Wn73N98seQJoM93Wya2ZmZmZmbbbaaqux+eabt3sYQ17bJ6vZ14B7gHMkfRaYC+wETCZd/vuvde3n5ry2+BIRcZ+ki4HDgd/nR9c8B2wG7AesDpwdEY/Vv3leWOnI/LLhwkoFlwOrSLoHWEBaDXgHYEfgPeCrETG/+S6bmZmZmZlZmUpMVvPZ1W7g34F9gM8BLwLnAKdFxJJebupI0r2phwF7A2sDrwN3ARdERNlqwHsDm5IWVnqkyXv8BNiTdHny+qQJ8wvAJaTJ8EO9HKuZmZmZmZmVkG8abp/u7u6YM2dOu4dhZmZmZmbWFpLuj4juhnWerLaPpEWkS5WrZn3g1XYPwgYtx5cNNMeYDSTHlw00x5gNpCrG16YR0XCRXE9W7SMkzSn7dcNsRTm+bKA5xmwgOb5soDnGbCB1WnxV4TmrZmZmZmZmZh/iyaqZmZmZmZlVjier1kizx/eYrQjHlw00x5gNJMeXDTTHmA2kjoov37NqZmZmZmZmleMzq2ZmZmZmZlY5nqyamZmZmZlZ5XiyagBIGi3pIkkLJS2TNF/S2ZLWa/fYrDokTZN0rqTZkl6XFJIua9JnV0k3SFoi6W1JD0s6QdKwHvrsK+l2SUslvSnpd5Km9/8eWZVI+qSkGZKulfS0pHdyDNwl6UhJDT+zHGPWCknflXSrpOdzjC2R9ICkUyV9sqSPY8z6TNIh+fMyJM0oadNyvEiaLum+3H5p7r/vwOyFVUX+jh4l6aWSPh17DPM9q4akLYF7gE8B1wHzgB2BycATwMSIWNy+EVpVSHoQ2A54E1gAjAEuj4iDS9p/Efgl8C5wFbAEmApsA1wTEfs36PN14Fxgce6zHJgGjAbOjIgT+3m3rCIkHQP8BHgRmAX8L7Ah8GVgOCmW9o/CB5djzFolaTnwB+Bx4BVgTWBnoBtYCOwcEc8X2jvGrM8kbQw8AgwD1gKOiogL69q0HC+Svg/8E+mz+BpgdeBA4BPA8RFx3kDtk7WXpPnAusDZDarfjIjv17Xv7GNYRDgN8QTcDATp4FYs/0EuP7/dY3SqRiL9gLEVIGBSjo/LStquQ/oiuAzoLpR3kX4cCeDAuj6bkQ6mi4HNCuXrAU/nPru0++/gNGDx9RnSB+gqdeUjSBPXAL5SKHeMOfUlzrpKyk/P//8fF8ocY059Tvmz8hbgGeB7+X8/Y0XjBdg1lz8NrFe3rcV5e5sN1H45tT2u5gPze9m2449hvgx4iJO0BbAXKfB/VFd9KvAWcIikNVfy0KyCImJWRDwV+ajVxDRgA+DKiJhT2Ma7wCn55bF1fY4A1gDOi4j5hT6vAd/JL4/p4/Ct4iLitoi4PiLeryt/CTg/v5xUqHKMWctyfDRydc63KpQ5xmxFfIP0I9zhpO9TjfQlXmqvT8/tan3mk77LrZHf06zjj2GerNpncv7rBl8Q3wDuBj5OukTKrBW12LqpQd2dwNvArpLW6GWfG+va2NDy55y/VyhzjFl/mprzhwtljjHrE0ljgTOAH0bEnT007Uu8OMZsDUkHSzpZ0j9Imlxy/2nHH8M8WbVtcv5kSf1TOd96JYzFBpfS2IqI94BngVWBLXrZ50XSL9OjJX28f4dqVSZpVeDQ/LL44ekYsz6TdKKkmZLOkjQb+DZponpGoZljzFqWj1k/J92+cHKT5i3FS77SbRTp3sQXG2zP39uGhhGkGDuddO/qbcBTkvaoa9fxx7BVV8abWKUNz/nSkvpa+borYSw2uPQltnrTZ83c7u0VGp11kjOATwM3RMTNhXLHmK2IE0kLeNXcBBwWEYsKZY4x64t/AyYAu0XEO03athov/t5mFwOzgceAN0gTza8DRwM3StolIh7KbTv+GOYzq9aMcu5lo62/9SW2HI9DjKRvkFa8nAcc0mr3nDvG7CMiYkREiHSG4sukL3wPSNq+hc04xuxDJO1IOpt6ZkT8tj82mfNW48XxNUhFxGl5jYeXI+LtiHg0Io4hLYz6MWBmC5ur/DHMk1Wr/WoyvKR+nbp2Zr3Vl9jqbZ/XV2Bc1iEkHQf8kPSIkckRsaSuiWPMVlj+wnctabHBTwKXFqodY9Zrhct/nwS+1cturcZLs/bNzorZ4FVbiHD3QlnHH8M8WbUncl52b0NtVcSye1rNypTGVv5A35y0WM4fe9lnJOmykwUR4UvnBjlJJwDnAY+SJqqNHnTuGLN+ExHPkX4YGSdp/VzsGLNWrEX6v48F3pUUtUR6wgLABbms9ozMluIlIt4CXgDWyvX1/L1t6Hol58UneHT8McyTVZuV870kfSgeJK0NTATeAe5d2QOzjndbzvdpULc7aZXpeyJiWS/7TKlrY4OUpH8BzgIeJE1UXylp6hiz/rZRzv+Sc8eYtWIZ8B8l6YHc5q78unaJcF/ixTFmjeyS8+LEs/OPYSvrga5O1U3AzaTrzo+vK/9BLj+/3WN0ql4iPe8ygMtK6tcBFtHag6g3p0IPonZqS1x9K/+f5wCfaNLWMebUanyNAUY0KF+FtKpmAHcXyh1jTv2SSPcRBjCjrrzleAF2zeVPA+sVyjfL23m3uC2nwZOAcY0+G4FNSStBB3Byobzjj2HKb25DmKQtSQH7KeA6YC6wEzCZdBnJrhGxuH0jtKqQtB+wX345Atib9Ave7Fz2akScWNf+GtJB70pgCfAF0rLo1wB/F3UHIUnHA+eQDpJXActJD7UeTVqw4kRsUJI0HbiEdFbrXBrfczU/Ii4p9HGMWa/ly8u/R3q+4DOkGNgQ2IO0wNJLwGcj4vFCH8eYrTBJM0mXAh8VERfW1bUcL5LOBP4RWECKw9WBA0j3XR8fEecN2M5Y2+Q4Ool0ZeSzpNWAtwQ+T5qA3gB8KSKWF/p09jGs3b8QOFUjARuTlsJ+MQfkc6SFTXo8s+E0tBL//8twWZrfoM9E0sHzNdIl5Y8A3wSG9fA+U4E7SAfht4DfA9Pbvf9ObY+vAG5v0M8x5tTbGPs08CPSJeavku7VWpr//zPLPvMcY04rmig5s1qobzlegOm53Vu53x3Avu3eV6cBjaM9gCtIK+T/Cfgz6czpb0jPI1dJv449hvnMqpmZmZmZmVWOF1gyMzMzMzOzyvFk1czMzMzMzCrHk1UzMzMzMzOrHE9WzczMzMzMrHI8WTUzMzMzM7PK8WTVzMzMzMzMKseTVTMzMzMzM6scT1bNzMysX0iaKSkkTWr3WMzMrPN5smpmZlYReaLXLE1q9zjNzMxWhlXbPQAzMzP7iNN6qJu/sgZhZmbWTp6smpmZVUxEzGz3GMzMzNrNlwGbmZl1qOI9opKmS3pA0juSXpF0kaQRJf22knSppBckLZe0ML/eqqT9MEnHSLpb0tL8Hk9LurCHPtMk3SfpbUlLJF0paVR/7r+ZmQ1uPrNqZmbW+b4J7AVcBdwE7AYcDkyStFNELKo1lLQDcAuwNvDfwOPAGOAg4IuSPhsRcwrtVwd+BewJPA/8Angd2Az4EnAX8FTdeL4GfCFv/w5gJ+AAYDtJ4yNiWX/uvJmZDU6erJqZmVWMpJklVe9GxBkNyqcAO0XEA4VtnAWcAJwBHJnLBFwKrAMcHBGXF9ofAFwJXCbpryPi/Vw1kzRRvR7YvzjRlLRG3la9fYAdIuKRQttfAH8PfBG4unTnzczMMkVEu8dgZmZmpNWAmzRZGhHrFtrPBE4FLoqII+u2NRx4DlgDWDcilkmaSDoT+tuI2LXB+88mnZXdIyLulDQMWAysDvxVRCxsMv7aeE6PiFPq6iYDtwFnRsSJTfbTzMzM96yamZlVTUSoJK1b0uWOBttYCjwIdAFjc/H2Ob+tZDu18gk5HwMMBx5uNlGtM6dB2fM5X6+F7ZiZ2RDmyaqZmVnne7mk/KWcD6/LXyxpXytfty5/ocXx/KlB2Xs5H9bitszMbIjyZNXMzKzzbVhSXlsNeGld3nCVYGBkXbvapNOr+JqZ2UrnyaqZmVnn26O+IN+zOh54F5ibi2sLME0q2U6t/A85n0easG4raaP+GKiZmVlvebJqZmbW+Q6RNKGubCbpst8rCiv43g08AewmaVqxcX69O/AkaREmIuIvwI+BjwHn59V/i31Wl7RBP++LmZkZ4EfXmJmZVU4Pj64B+K+IeLCu7EbgbklXk+473S2n+cBJtUYREZKmA78BrpJ0Hens6TbAfsAbwKGFx9YAnEZ6TupU4ElJ/5PbbUx6tus/A5f0aUfNzMx64MmqmZlZ9ZzaQ9180iq/RWcB15Keq3oA8CZpAnlyRLxSbBgRv5O0A3AK6fmpU4FXgSuAb0fEE3Xtl0vaBzgGOBSYDghYmN/zrtZ3z8zMrDk/Z9XMzKxDFZ5rOjkibm/vaMzMzPqX71k1MzMzMzOzyvFk1czMzMzMzCrHk1UzMzMzMzOrHN+zamZmZmZmZpXjM6tmZmZmZmZWOZ6smpmZmZmZWeV4smpmZmZmZmaV48mqmZmZmZmZVY4nq2ZmZmZmZlY5nqyamZmZmZlZ5fwfGg1iOPrvl80AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15,5))\n",
    "ax.plot(np.sqrt(lr_model_history.history['loss']), 'r', label='training')\n",
    "ax.plot(np.sqrt(lr_model_history.history['val_loss']), 'b' ,label='validation')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Loss', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)\n",
    "\n",
    "# Plot the accuracy\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,5))\n",
    "ax.plot(np.sqrt(lr_model_history.history['accuracy']), 'r', label='training')\n",
    "ax.plot(np.sqrt(lr_model_history.history['val_accuracy']), 'b' ,label='validation')\n",
    "ax.set_xlabel(r'Epoch', fontsize=20)\n",
    "ax.set_ylabel(r'Accuracy', fontsize=20)\n",
    "ax.legend()\n",
    "ax.tick_params(labelsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('//ibs9010/current_data/Data_Keshav/image/Classification_model/NeuronClassifierModels/BinaryClassifier_200epoch_4hidden_doubledata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on all Tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images: 4833\n",
      "Total testing images: 4833\n",
      "bkgd_image_counter: 4610 neuron_image_counter: 223\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "img_size = 70 # fix the size of the image\n",
    "Path = \"//ibs9010/current_data/Data_Keshav/Cropped_Images/S51_bigtile_new/\" \n",
    "#Path = \"//ibs9010/current_data/Data_Keshav/image/Classification_model/Data/Test/\"\n",
    "#Path = '//ibs9010/current_data/Data_Keshav/image/Classification_model/testingcrop/S055/'\n",
    "Testing_image = []# list of testing images\n",
    "image_name = []# list of image names\n",
    "\n",
    "for img in os.listdir(Path): #gives the images from the path\n",
    "    img_array = cv2.imread(os.path.join(Path,img),cv2.IMREAD_GRAYSCALE) # read every image in gray scale from the given path\n",
    "    Testing_image.append(img_array)\n",
    "    image_name.append(img)\n",
    "    \n",
    "print(\"Number of test images:\",len(Testing_image))\n",
    "#Running Inference\n",
    "Test_image = np.array(Testing_image).reshape(-1,img_size,img_size,1)\n",
    "#make an array of every element of list from Testing_image and then reshape them\n",
    "Test_image = Test_image/255.0\n",
    "scores = model.predict_classes(Test_image)\n",
    "\n",
    "# Results\n",
    "neuron_image_counter = bkgd_image_counter = 0\n",
    "for i in range(len(Test_image)):\n",
    "    #print(\"Image:\",image_name[i],\"with score:\",scores[i]) \n",
    "    if scores[i]==0:\n",
    "        bkgd_image_counter +=1\n",
    "    if scores[i]==1:\n",
    "        neuron_image_counter += 1\n",
    "    \n",
    "print(\"Total testing images:\",len(Testing_image))\n",
    "print(\"bkgd_image_counter:\",bkgd_image_counter,\"neuron_image_counter:\",neuron_image_counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving classified tiles into respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223\n"
     ]
    }
   ],
   "source": [
    "# saving the single neuron tiles into a particular folder for now - as a adhoc fix!\n",
    "import os\n",
    "import cv2\n",
    "dest_path = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Inference/BinaryClasses/singleneurontiles'\n",
    "#dest_path = \"//ibs9010/current_data/Data_Keshav/image/Classification_model/Inference/BinaryClasses/NewTestsingleneurontiles\"\n",
    "directory = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Data/Test/'\n",
    "\n",
    "# Delete all exiting images\n",
    "import glob\n",
    "os.chdir(dest_path)\n",
    "files=glob.glob('*.tif')\n",
    "for filename in files:\n",
    "    os.unlink(filename)\n",
    "    \n",
    "#need the images of class1 to be appended in a separate list\n",
    "single_image_list  = [] # contains list of filenames of single neurons\n",
    "#sn_images = [] # conatins tiles of single neurons #(actual images itself)\n",
    "for k in range(1,len(Test_image)):\n",
    "    if scores[k]==1:\n",
    "        #print(Test_image[i])\n",
    "        #print(\"Image \",image_name[k])\n",
    "        #sn_images.append(Test_image[i])\n",
    "        single_image_list.append(image_name[k])\n",
    "        \n",
    "print(len(single_image_list))  \n",
    "#image_name[i]\n",
    "for i in range(len(Test_image)):\n",
    "    if scores[i]==1:\n",
    "        #print(\"Image:\",image_name[i])\n",
    "        #print(\"TestImage:\",Test_image[i])\n",
    "        #cv2.imwrite(image_name[i], Test_image[i])\n",
    "        cv2.imwrite(os.path.join(dest_path,image_name[i]), Test_image[i]*255)\n",
    "        #pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Pickle files for classified tiles\n",
    "## To be used for generating landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating pickle file For Single neurons\n",
    "import pickle\n",
    "with open('//ibs9010/current_data/Data_Keshav/image/Classification_model/21july_binary_SN_MG48_3day_bs_S051.pkl', 'wb') as f:\n",
    "    pickle.dump(single_image_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Access is denied: '42.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-89ea1004b44b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*.tif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#need the images of class1 to be appended in a separate list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Access is denied: '42.tif'"
     ]
    }
   ],
   "source": [
    "# saving the bkgd neuron tiles into a particular folder for now - as a adhoc fix!\n",
    "import os\n",
    "import cv2\n",
    "#dest_path = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Inference/BinaryClasses/NewTestbackgroundneurontiles'\n",
    "dest_path = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Inference/BinaryClasses/backgroundneurontiles'\n",
    "directory = '//ibs9010/current_data/Data_Keshav/image/Classification_model/Data/Test/'\n",
    "\n",
    "# Delete all exiting images\n",
    "import glob\n",
    "os.chdir(dest_path)\n",
    "files=glob.glob('*.tif')\n",
    "for filename in files:\n",
    "    os.unlink(filename)\n",
    "\n",
    "#need the images of class1 to be appended in a separate list\n",
    "bkgd_image_list  = [] # contains list of filenames of single neurons\n",
    "#sn_images = [] # conatins tiles of single neurons #(actual images itself)\n",
    "for k in range(1,len(Test_image)):\n",
    "    if scores[k]==0:\n",
    "        #print(Test_image[i])\n",
    "        #print(\"Image \",image_name[k])\n",
    "        #sn_images.append(Test_image[i])\n",
    "        bkgd_image_list.append(image_name[k])\n",
    "        \n",
    "print(len(bkgd_image_list))  \n",
    "#image_name[i]\n",
    "for i in range(len(Test_image)):\n",
    "    if scores[i]==0:\n",
    "        #print(\"Image:\",image_name[i])\n",
    "        #print(\"TestImage:\",Test_image[i])\n",
    "        #cv2.imwrite(image_name[i], Test_image[i])\n",
    "        cv2.imwrite(os.path.join(dest_path,image_name[i]), Test_image[i]*255)\n",
    "        #pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
